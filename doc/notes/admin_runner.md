Sehr cool, dass du schon so weit bist â€“ das ist jetzt ein richtiges kleines Produkt ğŸ’ª
Ich geh die vier Fragen der Reihe nach durch und mache dir jeweils konkrete VorschlÃ¤ge + eine â€œEmpfehlung fÃ¼r jetztâ€.

---

## 1ï¸âƒ£ Bewirtschaftung der LÃ¤ufer (aktiv, E-Mail, Nummer, â€¦)

Im Moment entstehen die LÃ¤ufer aus dem Excel-Import, und `import_excel.py` erzeugt `runners.json`. Es gibt drei sinnvolle Strategien fÃ¼r die Pflege:

### Option A: â€œMaster-Excelâ€ fÃ¼r Kontakte (empfohlen kurzfristig)

Du hast ja schon `sola_kontakte.xlsx`. Wir kÃ¶nnen das so machen:

* `sola_kontakte.xlsx` wird die **Masterliste** fÃ¼r:

  * `email`
  * `mobile`
  * `active`
  * ggf. `company`/`is_external` Overrides

* `import_excel.py`:

  * liest wie heute die Laufdaten aus `SOLA_1998-2025.xlsx`
  * liest zusÃ¤tzlich `sola_kontakte.xlsx`
  * matched Ã¼ber `runner_id` (oder â€œLÃ¤uferâ€-Name wie bisher)
  * Ã¼berschreibt:

    * Dummy-E-Mail â†’ echte E-Mail
    * Dummy-Mobile â†’ echte Mobile
    * `active` Flag

**Vorteile:**

* Du pflegst alles in **Excel**, nicht in JSON.
* Ã„nderungen an Kontaktdaten = Excel speichern â†’ `make import` â†’ JSON frisch.
* Kein Risiko, dass Ã„nderungen im JSON beim nÃ¤chsten Import Ã¼berbÃ¼gelt werden.

> Wir mÃ¼ssen dazu nur `import_excel.py` um 2â€“3 Felder im `CONTACT_COLUMNS`-Block erweitern (z.B. `active`, `company`, `is_external_override`).

---

### Option B: Admin-UI in Streamlit (mittelfristig sexy)

Eine zusÃ¤tzliche Tab-Seite â€œAdminâ€:

* Dropdown / Suche nach LÃ¤ufer
* Formular:

  * Vorname, Nachname (readonly oder bearbeitbar)
  * Firma
  * extern (Checkbox)
  * aktiv (Checkbox)
  * E-Mail, Mobile editierbar
* Button â€œSpeichernâ€:

  * schreibt geÃ¤ndertes `runners.json` zurÃ¼ck
    (dann Volume `/data/processed` im Docker nicht `:ro`, sondern `:rw`)

**Vorteil:**
Direkt in der App editieren, kein Excel Ã¶ffnen.

**Nachteil:**
Komplexer (File-Locks, Versionierung, Race-Import darf LÃ¤ufer nicht wieder Ã¼berschreiben). Langfristig eher mit DB sauber.

---

### Option C: Direkt JSON bearbeiten

Kannst du natÃ¼rlich auch mit VS Code machen, ist aber:

* fehleranfÃ¤llig,
* doof, sobald du viele Ã„nderungen machst,
* beim nÃ¤chsten `make import` wieder Ã¼berschrieben.

**=> Empfehlung:**

**Jetzt sofort:**
â†’ Option A: `sola_kontakte.xlsx` als Master, Script so erweitern, dass `active`, `email`, `mobile` usw. daraus kommen.

**SpÃ¤ter:**
â†’ Admin-Tab in der Streamlit-App (auf Basis der JSONs).

---

## 2ï¸âƒ£ NÃ¤chstes Jahr: wie kommen die neuen Daten rein?

Kurz gesagt: ja, du wirst jedes Jahr einmal â€œExcel anfassenâ€. Aber wir kÃ¶nnen den Prozess klar definieren, damit es nicht chaotisch wird.

### Vorschlag fÃ¼r deinen Workflow:

1. **Nach dem Lauf** holst du dir die Resultate (entweder:

   * vom offiziellen Excel,
   * oder spÃ¤ter automatisiert von TrackMaxx).

2. Du hast **ein â€œMaster-Excelâ€**:

   * `data/raw/SOLA_1998-2025.xlsx`
     (ggf. irgendwann `SOLA_1998-2030.xlsx` â€¦)
   * gleiche Kopfzeilen wie heute
   * neues Jahr = einfach unten dranhÃ¤ngen oder eigenes Sheet, das `import_excel.py` mitliest.

3. Du pflegst:

   * Distanz
   * Rang / Zeit / Pace
   * `Teams` (Anzahl)
   * LÃ¤ufer (Namenskonventionen gleich lassen)

4. Dann:

```bash
make import
```

â†’ JSONs aktualisiert, App zeigt das neue Jahr automatisch.

### Alternative:

Pro Jahr ein separates File:

* `SOLA_1998.xlsx`
* `SOLA_1999.xlsx`
* â€¦
* `import_excel.py` iteriert Ã¼ber alle Dateien im `raw/`-Ordner.

Vorteil:
Mehr Ordnung, leichter zu versionieren.

Wenn du willst, kann ich dir `import_excel.py` so umbauen, dass es:

* **alle `SOLA_*.xlsx`** nacheinander einliest,
* und daraus ein groÃŸes `DataFrame` macht.

---

## 3ï¸âƒ£ CI/CD mit privatem GitHub-Repo

Sehr passend:

* **Code + Datenmodell** auf GitHub (privat),
* Docker-Image erbauen,
* als Artefakt nach **GHCR oder OCI** schieben.

### 3.1. GitHub Actions minimal Setup

Du kÃ¶nntest in `.github/workflows/build.yml` so etwas haben:

```yaml
name: Build & Test

on:
  push:
    branches: [ main ]
  pull_request:

jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run import script
        run: |
          python tools/import_excel.py

      # Optional: Tests, Lint, etc.
      # - name: Run tests
      #   run: pytest
```

Damit stellst du sicher:

* Excel â†’ JSON lÃ¤uft auch in CI,
* das Repo ist â€œgrÃ¼nâ€.

### 3.2. Docker Build & Push (z.B. nach GHCR)

ZusÃ¤tzlicher Job:

```yaml
  docker-build:
    runs-on: ubuntu-latest
    needs: build-test
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ghcr.io/${{ github.repository_owner }}/sola-history:latest
```

**Wenn du lieber direkt nach OCI pushen willst:**

* in GitHub Secrets z.B. `OCI_USER`, `OCI_TENANCY`, `OCI_AUTH_TOKEN` etc.
* `docker/login-action` mit `iad.ocir.io` und deinen Credentials
* `tags: iad.ocir.io/<tenancy-namespace>/sola-history:latest`

Dann kannst du auf OCI einfach Container Instances von diesem Image starten.

---

## 4ï¸âƒ£ Planungsmodul: wer lÃ¤uft welche Strecke, wann muss er/sie wo sein?

Das wird echt ein cooles Feature ğŸ˜

### 4.1. Was wir dafÃ¼r brauchen (Datenmodell)

Neue EntitÃ¤t, z.B. `race_plan`:

```json
{
  "race_id": "sola-2026",
  "race_date": "2026-05-XX",
  "race_start_time": "09:00",
  "teams": [
    {
      "team_id": "sola-2026-team-310",
      "name": "Optimizers",
      "legs": [
        {
          "leg_id": "sola-2026-leg-01",
          "leg_number": 1,
          "runner_id": "andrea.kennel",
          "expected_pace_sec_per_km": 320,
          "expected_time_seconds": 1400,
          "planned_start": "09:00",
          "planned_finish": "09:23"
        }
      ]
    }
  ]
}
```

Berechnung:

* Distanz pro Leg haben wir ja aus `legs.json`.
* Entweder:

  * LÃ¤ufer:in gibt **Pace** an â†’ `time = pace * dist`
  * oder du gibst direkt erwartete Zeit ein.

Kette:

* Leg1 start = Race-Start
* Leg1 finish = start + expected_time
* Leg2 start = Leg1 finish (+ evtl. Ãœbergabepuffer)
* usw.

Darauf kannst du dann:

* Pro LÃ¤ufer:

  * â€œDu musst spÃ¤testens um X Uhr am Start der Etappe Y seinâ€
  * â€œDeine voraussichtliche Ankunft am Ziel ist â€¦â€

### 4.2. UI-Idee in Streamlit

Neuer Tab: **â€œPlanungâ€**

1. **Step 1 â€“ Setup**

   * wÃ¤hle Jahr (oder â€œnÃ¤chstes Rennenâ€)
   * Eingabe: Race-Datum, Startzeit
   * Team selektieren / anlegen

2. **Step 2 â€“ Zuteilung**

   * Tabelle `Leg 1..14`
   * Spalte â€œRunnerâ€ â†’ Dropdown aus `runners.json`
   * Spalte â€œErwartete Paceâ€ â†’ Input (mm:ss/km) oder direkt Sekunden
   * Button â€œPlan berechnenâ€

3. **Step 3 â€“ Ergebnis**

   * Tabelle je Leg:

     * Leg, Runner, Distanz, expected time, geplante Start-/Zielzeit
   * Tabelle je Runner:

     * â€œEtappe X, Start um hh:mm, sei am Treffpunkt um hh:mm-10â€
   * Optional: Export als CSV/Excel oder PDF.

4. **Persistenz**

   * speichern als `data/processed/plans.json`
   * oder `data/raw/SOLA_PLAN_2026.xlsx` und daraus wieder JSON generieren (analog Resultate).

### 4.3. SpÃ¤ter nice-to-have

* Integration mit Strava (real pace vs. predicted).
* Plan vs. Ist im Nachhinein vergleichen.
* â€œWer hat sich am meisten verschÃ¤tzt?â€ ğŸ˜„

---

## Zusammengefasst / Empfehlung

* **Runner-Pflege**:
  Kurzfristig via `sola_kontakte.xlsx` als Master (Script erweitern).

* **Neues Jahr**:
  Jahresdaten in Master-Excel hÃ¤ngen â†’ `make import` â†’ fertig.
  Mittelfristig evtl. ein File pro Jahr + Loop im Script.

* **CI/CD**:
  GitHub Actions:

  * Job: Excelâ†’JSON testen
  * Job: Docker-Image bauen & nach GHCR/OCI pushen

* **Planung**:
  eigenes JSON-Modell fÃ¼r `race_plan`,
  neuer Streamlit-Tab â€œPlanungâ€ mit:

  * Runner-Zuteilung pro Leg
  * erwartete Pace / Zeit
  * automatischer Zeitplan.

Wenn du mÃ¶chtest, kÃ¶nnen wir als nÃ¤chsten Schritt sehr konkret:

* `import_excel.py` um `active` / Kontaktdaten erweitern
* und/oder ein erstes Datenmodell + JSON-Stub fÃ¼r `plans.json` definieren und gleich eine einfache Planungs-Tab in deine App einbauen.
