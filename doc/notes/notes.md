Nice, Meilenstein erreicht üéâ
Jetzt machen wir aus dem Prototyp eine ‚Äúrichtige‚Äù Codebasis.

Ich schlage folgendes Vorgehen vor:

1. **Repo-Struktur & .gitignore aufr√§umen**
2. **Doku-Ger√ºst anlegen (Root, data/, tools/, CI/CD)**
3. **Code ins Git committen**

Ich gebe dir direkt konkrete Snippets/Dateien, die du √ºbernehmen kannst.

---

## 1. Repo-Struktur & .gitignore

Deine Struktur ist schon gut, wir sch√§rfen nur ein bisschen:

**Zielstruktur (logisch):**

```text
.
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ raw/          # echte Excels ‚Äì bleiben lokal, nicht in git
‚îÇ   ‚îú‚îÄ‚îÄ processed/    # generierte JSONs ‚Äì nicht in git
‚îÇ   ‚îú‚îÄ‚îÄ schema/       # JSON Schema ‚Äì ins git
‚îÇ   ‚îî‚îÄ‚îÄ README.md     # Erkl√§rung Datenhandling
‚îú‚îÄ‚îÄ tools
‚îÇ   ‚îú‚îÄ‚îÄ import_excel.py
‚îÇ   ‚îú‚îÄ‚îÄ test.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ doc
    ‚îú‚îÄ‚îÄ README.md         # Projektbeschreibung, verlinkt auf andere Docs
    ‚îî‚îÄ‚îÄ ci_cd.md          # CI/CD, Deployment, Security
```

### 1.1 `.gitignore`

Lege im Repo-Root eine `.gitignore` an (oder erg√§nze), z.B.:

```gitignore
# Python
venv/
__pycache__/
*.pyc

# macOS
.DS_Store

# Local env
.env
*.env

# Data: raw + processed nicht ins Repo
data/raw/*
data/processed/*

# aber Schema und ggf. Sampledaten versionieren
!data/schema/
!data/schema/*
!data/sample/
!data/sample/*

# Excel / sensible Dateien generell eher nicht
*.xlsx
*.xls

# Streamlit
.streamlit/
```

> Optional: Wenn du sp√§ter anonymisierte Beispiel-Daten haben willst, legst du `data/sample/` an und checkst die ein.

---

## 2. Dokumentation anlegen

### 2.1 Root-README (`README.md`)

Vorschlag f√ºr dein aktuelles Setup:

````markdown
# üèÉ‚Äç‚ôÇÔ∏è Sola History

Internes Analyse- und Planungstool f√ºr die SOLA-Stafette Z√ºrich (Accenture / Trivadis Teams).

Ziele:

- Historische Daten der letzten Jahre auswerten (Teams, L√§ufer:innen, Etappen)
- Highlights und Statistiken (Top-Distanzen, Teilnahmen, Bestzeiten, Teamr√§nge)
- Planung f√ºr zuk√ºnftige SOLA-Rennen (Etappen, Paces, Zeitplan)
- Admin-Bereich f√ºr L√§ufer-Stammdaten (Kontaktdaten, T-Shirt, Food, etc.)

## üîß Tech-Stack

- [Python 3.11](https://www.python.org/)
- [Streamlit](https://streamlit.io/) ‚Äì UI
- [pandas](https://pandas.pydata.org/) ‚Äì Datenverarbeitung
- Docker / Docker Compose ‚Äì Container
- (sp√§ter) OCI f√ºr Hosting

## üìÅ Projektstruktur

```text
.
‚îú‚îÄ‚îÄ app.py              # Streamlit App
‚îú‚îÄ‚îÄ Dockerfile          # Multi-Stage Build
‚îú‚îÄ‚îÄ docker-compose.yml  # Lokales Deployment
‚îú‚îÄ‚îÄ Makefile            # Komfort-Targets (venv, import, run, build)
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ raw/            # Produktiv-Excels (NICHT im Git)
‚îÇ   ‚îú‚îÄ‚îÄ processed/      # generierte JSONs (NICHT im Git)
‚îÇ   ‚îú‚îÄ‚îÄ schema/         # JSON-Schema f√ºr Daten
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ tools
‚îÇ   ‚îú‚îÄ‚îÄ import_excel.py # Excel ‚Üí JSON Konverter
‚îÇ   ‚îú‚îÄ‚îÄ test.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ doc
    ‚îú‚îÄ‚îÄ README.md       # zus√§tzliche Doku
    ‚îî‚îÄ‚îÄ ci_cd.md        # CI/CD, Deployment, Security
````

## üöÄ Lokale Entwicklung

### 1. Virtualenv & Dependencies

```bash
make venv        # optional, falls nicht schon vorhanden
make install     # installiert requirements in venv
```

### 2. Daten importieren

Lege die Excels hier ab:

* `data/raw/sola_history.xlsx`
* `data/raw/sola_contacts.xlsx`

Dann:

```bash
make import
```

Ergebnis: JSON-Dateien in `data/processed/` (runners, teams, results, legs, races).

### 3. App lokal starten

```bash
make run
# oder direkt
venv/bin/streamlit run app.py
```

Standard-Passwort (lokal): `sola`
(√ºberschreibbar via Environment-Variable `SOLA_APP_PASSWORD`)

## üê≥ Docker

Build & Run:

```bash
make build      # docker build
make up         # docker compose up
```

Die App l√§uft dann unter: [http://localhost:8501](http://localhost:8501)

Daten als Volume mounten (Beispiel in `docker-compose.yml`):

```yaml
services:
  sola-history:
    image: sola-history:latest
    volumes:
      - ./data/processed:/app/data/processed:ro
```

## üîê Daten & Security

* **Echte Daten** (Excels in `data/raw/`) kommen **nicht** ins Repo.
* `data/processed/*.json` werden aus den Excels generiert ‚Üí ebenfalls nicht ins Repo.
* Zugriff auf die App ist mit einem simplen Passwort gesch√ºtzt (`SOLA_APP_PASSWORD`).
* F√ºr produktive Nutzung (z.B. auf OCI) sollten zus√§tzlich Netzwerkkontrollen (VPN, IP-Restriktionen, etc.) verwendet werden.

Details zu CI/CD und Deployment: siehe [`doc/ci_cd.md`](doc/ci_cd.md).

````

---

### 2.2 `data/README.md`

```markdown
# üìÇ data/ ‚Äì Datenstruktur & Richtlinien

Dieses Verzeichnis enth√§lt alle Daten f√ºr die Sola History App.

## Struktur

```text
data/
‚îú‚îÄ‚îÄ raw/         # Original-Excel-Dateien (SOLA History & Kontakte)
‚îú‚îÄ‚îÄ processed/   # generierte JSON-Dateien ‚Üí Input f√ºr app.py
‚îú‚îÄ‚îÄ schema/      # JSON-Schema f√ºr die processed-Dateien
‚îî‚îÄ‚îÄ sample/      # optionale, anonymisierte Beispiel-Daten
````

## raw/

* `sola_history.xlsx`
  Historische SOLA-Daten, eine Zeile pro Etappe / L√§ufer / Jahr.

* `sola_contacts.xlsx`
  Kontaktdaten und Stammdaten der L√§ufer:innen.

> ‚ö†Ô∏è **Wichtig:**
> `data/raw/` enth√§lt personenbezogene Daten und geh√∂rt **nicht** ins Git-Repository.

## processed/

Wird durch `tools/import_excel.py` erzeugt (`make import`):

* `runners.json`
* `teams.json`
* `legs.json`
* `races.json`
* `results.json`
* `runners_overrides.json` (wird von der App im Admin-Tab beschrieben)

Diese Dateien dienen als direkte Datenquelle f√ºr `app.py`.

> ‚ö†Ô∏è Ebenfalls **nicht** ins Repo, da sie aus den sensitiven Rohdaten generiert werden.

## schema/

* `sola.schema.json` ‚Äì Definition der JSON-Struktur f√ºr `processed/`.
* Kann erweitert werden, sobald weitere Felder dazukommen.

## sample/ (optional)

Hier k√∂nnen anonymisierte Beispiel-Daten liegen, die ins Repo eingecheckt werden d√ºrfen, z.B.:

* `sample_runners.json`
* `sample_teams.json`
* ‚Ä¶

Die App k√∂nnte sp√§ter einen ‚ÄûDemo-Mode‚Äú bekommen, der diese Daten nutzt.

````

---

### 2.3 `tools/README.md` (angepasst auf deine aktuellen Dateien)

```markdown
# üõ† tools/ ‚Äì Data Processing Utilities

Dieser Ordner enth√§lt Hilfsskripte f√ºr den Datenimport, Tests & Validierung.

## üìÑ import_excel.py

Zentrale Aufgaben:

- Lesen der Excel-Dateien:

  - `data/raw/sola_history.xlsx`
  - `data/raw/sola_contacts.xlsx`

- Aufbereitung & Normalisierung
- Generierung aller JSON-Dateien in `data/processed/`
- Logik f√ºr:
  - Runner-ID (ASCII, ohne Umlaute, z.B. `konrad.haefeli`)
  - Mapping der Kontakte auf die History-Daten
  - Zeit- und Pace-Felder in Sekunden
  - Team-Zwischenst√§nde pro Etappe
  - Flags wie `is_external`, `active`, Firma etc.

### Nutzung

```bash
make import
````

oder direkt:

```bash
venv/bin/python tools/import_excel.py
```

## üß™ test.py

Kleine Tests & Debug-Snippets f√ºr den Import.

Ausf√ºhrung:

```bash
venv/bin/python tools/test.py
```

## Workflow

1. Excel-Dateien in `data/raw/` aktualisieren
2. `make import` ausf√ºhren
3. Generierte JSONs in `data/processed/` pr√ºfen
4. App neu starten (`make run` / Docker)

Falls sich das Excel-Layout √§ndert (neue Spalten, neue Namen), muss `tools/import_excel.py` angepasst werden.

````

---

### 2.4 `doc/README.md`

```markdown
# üìö Dokumentation

Hier liegt die zus√§tzliche Projekt-Dokumentation.

- `ci_cd.md` ‚Äì Entwurf f√ºr CI/CD, Deployment, Security & Datenstrategie
````

Und eine erste `doc/ci_cd.md`-Skizze (so wie wir es vorher grob geplant hatten):

```markdown
# CI/CD, Deployment & Security (Draft)

## Ziele

- Automatischer Build des Docker-Images bei √Ñnderungen am Code (GitHub Actions)
- Push des Images in eine Container Registry (z.B. OCI Container Registry)
- Deployment der App auf OCI (Container Instance, VM oder OKE)
- Sensible Daten bleiben getrennt von Code (kein Commit von Rohdaten)

## Repositories

Empfohlene Trennung:

- **Public Repo** (GitHub):  
  - Code (`app.py`, `tools/`, `Dockerfile`, `Makefile`, `doc/`, `data/schema/`)
  - Optionale anonymisierte Beispieldaten (`data/sample/`)

- **Private Datenhaltung** (nicht in GitHub):  
  - `data/raw/sola_history.xlsx`
  - `data/raw/sola_contacts.xlsx`
  - ggf. generierte `data/processed/*.json`

## GitHub Actions (Beispiel-Idee)

Workflows:

1. **build-and-test.yml**
   - Trigger: Push auf `main` oder PR
   - Schritte:
     - Checkout
     - `make venv && make install`
     - `make import` mit Sample-Dateien (nicht mit echten Daten)
     - Optional: Tests

2. **build-and-push-image.yml**
   - Trigger: Tag `v*`
   - Schritte:
     - Docker login in OCIR (Secrets: `OCIR_USERNAME`, `OCIR_PASSWORD`, `OCIR_REPO`)
     - `docker build -t $OCIR_REPO:tag .`
     - `docker push $OCIR_REPO:tag`

## Deployment nach OCI (Skizze)

Variante 1: **Compute Instance + Docker Compose**

- Compute VM in OCI
- Docker + Docker Compose installiert
- App-Container + Volume-Mount f√ºr `data/processed`
- Zugriff gesch√ºtzt via:
  - Security Lists / NSG (IP-Restriktion)
  - VPN

Variante 2: **Container Instance**

- Container-Image aus OCIR
- Environment-Variables:
  - `SOLA_APP_PASSWORD`
- Volumes / Mounts f√ºr Daten
- Network-Policies analog

## Security & Privacy

- Personenbezogene Daten:
  - Namen, Kontaktdaten, Laufzeiten ‚Üí DSG/DSGVO relevant
- Ma√ünahmen:
  - Keine Rohdaten im √∂ffentlichen Git
  - Zugriff auf App nur f√ºr berechtigte Personen
  - Passwort nicht hardcodieren ‚Üí `SOLA_APP_PASSWORD` via Secret
  - Logs nicht mit vollst√§ndigen Personenlisten f√ºllen
```

---

## 3. Code ins Git √ºbernehmen ‚Äì konkrete Schritte

Im Repo-Root:

```bash
git init
git add .
git status    # kurz pr√ºfen, dass data/raw & data/processed NICHT dabei sind
git commit -m "Initial commit: Sola History prototype with app, tools and docs"
```

Dann auf GitHub ein Repo anlegen (z.B. `oehrlis/sola-history`) und:

```bash
git remote add origin git@github.com:oehrlis/sola-history.git
git push -u origin main
```

> Wenn du das Repo *sp√§ter* aufteilst (public/private), k√∂nnen wir eine saubere Strategie mit Submodulen oder nur ‚ÄûDaten ausserhalb von git‚Äú definieren.

---

Wenn du willst, kann ich dir als n√§chsten Schritt:

* eine konkrete **GitHub Actions Workflow-Datei** f√ºr Build + Lint + Docker-Build schreiben und
* eine minimalistische **OCI-Deployment-Skizze** (z.B. Bash + `docker compose pull/up` auf einer Compute-VM).

Alles klar, dann bekommt dein Repo jetzt eine ‚Äûerwachsene‚Äú CI üòÑ

Ich gebe dir eine **fertige GitHub Actions Workflow-Datei**, die:

* bei **push & PR** auf `main`:

  * Python 3.11 einrichtet
  * Dependencies installiert
  * einen kleinen Smoke-Test macht (Syntaxcheck f√ºr `app.py`)
  * optional `import_excel.py` ausf√ºhrt, **falls** Excel-Dateien vorhanden sind
* bei **Tags** (z.B. `v1.0.0`) zus√§tzlich:

  * ein Docker-Image baut
  * das Image in ein Registry-Repo pusht (z.B. OCI oder Docker Hub, via Secrets)

---

## 1. Datei anlegen

Lege diese Datei an:

`.github/workflows/ci.yml`

Mit folgendem Inhalt:

```yaml
name: Sola History CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  # Manuelle Ausf√ºhrung m√∂glich
  workflow_dispatch:
  # Docker-Build & Push nur bei Tags (z.B. v1.0.0)
  push:
    tags:
      - "v*"

jobs:
  # ------------------------------------------------------
  # Job 1: Lint / Smoke-Test mit Python
  # ------------------------------------------------------
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends tzdata
          sudo rm -rf /var/lib/apt/lists/*

      - name: Create virtualenv & install Python dependencies
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
          # optional: fpdf f√ºr PDF-Export
          pip install fpdf || true

      - name: Optional: run Excel import if input exists
        run: |
          source venv/bin/activate
          if [ -f data/raw/sola_history.xlsx ] && [ -f data/raw/sola_contacts.xlsx ]; then
            echo "Found Excel files in data/raw ‚Äì running import_excel.py ..."
            python tools/import_excel.py
          else
            echo "No Excel input found in data/raw ‚Äì skipping import step."
          fi

      - name: Smoke test ‚Äì check app.py syntax
        run: |
          source venv/bin/activate
          python -m py_compile app.py

      # Hier k√∂nntest du sp√§ter pytest einh√§ngen
      # - name: Run tests
      #   run: |
      #     source venv/bin/activate
      #     pytest

  # ------------------------------------------------------
  # Job 2: Docker-Image bauen & in Registry pushen
  # Nur bei Tags (vX.Y.Z), und erst wenn test ok ist
  # ------------------------------------------------------
  docker:
    needs: test
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')

    env:
      # Beispiel: region.ocir.io/tenancy-namespace/sola-history
      REGISTRY: ${{ secrets.REGISTRY_URL }}
      IMAGE_NAME: ${{ secrets.IMAGE_NAME }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_PASSWORD }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
```

---

## 2. Secrets / Umgebungen vorbereiten

In GitHub unter **Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret**:

* `REGISTRY_URL`
  z.B. f√ºr OCI: `eu-zurich-1.ocir.io/<tenancy-namespace>`
* `IMAGE_NAME`
  z.B. `sola-history`
* `REGISTRY_USERNAME`
  z.B. `tenancy-namespace/<user-ocid>` oder Docker-Hub-User
* `REGISTRY_PASSWORD`
  Passw√∂rter/API-Token/OCI Auth-Token

> Wenn du erstmal nur CI ohne Push willst, kannst du den ganzen `docker`-Job auch einfach drin lassen ‚Äì er l√§uft nur, wenn du einen Tag `v*` pushst.

---

## 3. N√§chste Schritte

1. `.github/workflows/ci.yml` einchecken:

   ```bash
   git add .github/workflows/ci.yml
   git commit -m "Add CI/CD workflow for Sola History"
   git push
   ```
2. Auf GitHub unter **Actions** schauen, ob der `Sola History CI/CD` Workflow sauber durchl√§uft.
3. Wenn alles passt: ersten Tag setzen und schauen, ob der Docker-Job l√§uft:

   ```bash
   git tag v0.1.0
   git push --tags
   ```

Wenn du magst, k√∂nnen wir als n√§chstes:

* die `REGISTRY_URL` konkret auf **OCIR-Format** anpassen
* oder ein zweites, einfacheres Workflow-File nur f√ºr CI ohne Registry bauen.

Perfekt, dann machen wir jetzt den ‚ÄûOCI-Plan auf Papier‚Äú, den du sp√§ter in Ruhe umsetzen kannst. Kein Klicki-Bunti, sondern eine klare Skizze, die zu deinem Setup passt.

Ich skizziere zwei minimalistische Varianten:

* **Variante A:** OCI *Container Instance* (am wenigsten Ops)
* **Variante B:** Compute-VM mit Docker Compose (klassisch, mehr Kontrolle)

---

## Annahmen (f√ºr beide Varianten)

Damit die Skizze konkret ist, nehme ich folgendes an:

* Dein Image liegt in **OCIR** unter so etwas wie
  `eu-zurich-1.ocir.io/<tenancy-namespace>/sola-history:latest`
* Die App l√§uft im Container auf Port **8501**
* Passwort kommt √ºber Env-Var: `SOLA_APP_PASSWORD`
* Daten:

  * F√ºr den Anfang: JSONs sind **ins Image gepackt** oder du synchronisierst sie manuell auf die Instanz
  * Sp√§ter kannst du auf Object Storage / File Storage erweitern

---

## Variante A ‚Äì OCI Container Instance (Minimal-Deployment)

Das ist die ‚Äûschnell & sauber‚Äú-Variante: kein eigenes OS patchen, einfach Container laufen lassen.

### 1. Voraussetzungen

* OCIR ist eingerichtet
* Du hast:

  * `REGION` (z.B. `eu-zurich-1`)
  * `tenancy-namespace` (OCIR Namespace)
  * OCIR-Repo: `eu-zurich-1.ocir.io/<tenancy-namespace>/sola-history:latest`
* Ein bestehendes:

  * **VCN** + **Subnet** (public oder private, je nach Zugriff)
  * Optional: **Network Security Group (NSG)**

### 2. Minimal-Setup (Konsole ‚Äì grob)

1. **Container Instance erstellen**

   * *Developer Services ‚Üí Containers ‚Üí Container Instances*
   * ‚ÄûCreate Container Instance‚Äú
   * Name: `sola-history-ci`
   * Compartment: dein Standard-Compartment
   * **Shape:** klein reicht (z.B. `CI.Standard.E2.1`)
   * **Subnet:**

     * Public Subnet: wenn du direkt via Public IP zugreifen willst
     * Private + VPN/Bastion: wenn es internal only sein soll

2. **Container hinzuf√ºgen**

   * Image: `eu-zurich-1.ocir.io/<tenancy-namespace>/sola-history:latest`
   * Command: leer lassen (nimmt `CMD` aus Dockerfile ‚Üí Streamlit)
   * Ports:

     * Container-Port: `8501`
   * Env Vars:

     * `SOLA_APP_PASSWORD=deinGeheimesPasswort`
   * Optional: Volume/Filesystem einh√§ngen, wenn Daten getrennt liegen

3. **Netzwerk erlauben**

   * Wenn Public Subnet:

     * Security List / NSG-Regel: Ingress TCP Port 8501 von deiner IP (oder B√ºro-Netz)
   * URL: `http://<Public-IP>:8501`

> Minimal: damit bist du schon online, mit sehr wenig Moving Parts.

### 3. CLI-Skizze (wenn du lieber skriptst)

Wenn du sp√§ter automatisieren willst, kannst du das mit `oci` machen (nur grobe Skizze):

```bash
oci container-instances container-instance create \
  --compartment-id <COMPARTMENT_OCID> \
  --display-name "sola-history-ci" \
  --shape-name "CI.Standard.E2.1" \
  --availability-domain "<AD_NAME>" \
  --vnics '[{"subnetId": "<SUBNET_OCID>", "displayName": "sola-ci-vnic"}]' \
  --containers '[
    {
      "displayName": "sola-history",
      "imageUrl": "eu-zurich-1.ocir.io/<tenancy-namespace>/sola-history:latest",
      "command": [],
      "environmentVariables": {
        "SOLA_APP_PASSWORD": "geheim"
      },
      "ports": [
        {
          "containerPort": 8501,
          "protocol": "TCP"
        }
      ]
    }
  ]'
```

Sp√§ter kannst du:

* Image-Tag per CI/CD aktualisieren
* Container Instance √ºber Script neu erstellen/rollen

---

## Variante B ‚Äì Compute-VM + Docker Compose

Klassisch: eine kleine VM, darauf Docker, dein Compose-Setup, und los.

### 1. Compute Instance anlegen

* *Compute ‚Üí Instances ‚Üí Create*
* Shape: z.B. `VM.Standard.E3.Flex` mit 1 OCPU / 4 GB RAM
* Image: Oracle Linux oder Ubuntu, was dir lieber ist
* VCN/Subnet wie oben (Public oder Private)
* SSH Key hinterlegen

### 2. Auf der VM (SSH)

Grober Ablauf:

```bash
# 1. System aktualisieren
sudo dnf update -y   # oder apt-get auf Ubuntu

# 2. Docker installieren (Beispiel Oracle Linux)
sudo dnf install -y docker
sudo systemctl enable docker
sudo systemctl start docker
sudo usermod -aG docker $USER

# ggf. neu einloggen, damit docker group aktiv ist
```

Optional Docker Compose (falls nicht in Docker integriert):

```bash
sudo curl -L "https://github.com/docker/compose/releases/download/v2.29.0/docker-compose-$(uname -s)-$(uname -m)" \
  -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

### 3. Repo / Config auf die VM

Variante minimal:

* Du brauchst nur:

  * `docker-compose.yml`
  * keine Datendateien im Repo, sondern mountest sie von `/opt/sola/data`

Beispiel-`docker-compose.yml` (angepasst auf OCIR):

```yaml
services:
  sola-history:
    image: eu-zurich-1.ocir.io/<tenancy-namespace>/sola-history:latest
    container_name: sola-history
    restart: unless-stopped
    environment:
      - SOLA_APP_PASSWORD=${SOLA_APP_PASSWORD}
    ports:
      - "8501:8501"
    volumes:
      - /opt/sola/data/processed:/app/data/processed:ro
```

Auf der VM:

```bash
mkdir -p /opt/sola/data/processed
# JSONs hinkopieren (scp/rsync)
# scp data/processed/* opc@<vm-ip>:/opt/sola/data/processed/

export SOLA_APP_PASSWORD="geheim"
docker compose up -d
```

Ab dann: `http://<VM-Public-IP>:8501`

---

## Security-Minimum in beiden Varianten

Egal ob Container Instance oder VM:

* **Nicht** das Ding ‚Äûoffen ins Internet‚Äú, wenn dort echte Namen/Kontakte drin sind.
* Minimal:

  * Security List / NSG:

    * Ingress TCP Port 8501
    * Source: deine B√ºro-IP, Heimnetz oder VPN-Range
* App selbst:

  * Passwort via `SOLA_APP_PASSWORD` aus Secret (kein Hardcoding im Code)
* Logs:

  * Aufpassen, dass du keine sensiblen Daten in irgendwelche externen Logsysteme schiebst.

---

## Wie w√ºrde ich pers√∂nlich starten?

F√ºr deinen Use Case (interne Spielwiese, kleiner Nutzerkreis):

1. **Variante A: Container Instance**

   * Einmal im Console klicken, Image angeben, Env setzen, fertig.
   * Netzwerk so einschr√§nken, dass nur du / dein Team Zugriff habt.
2. *Sp√§ter*, wenn du mehr Kontrolle willst (Volumes, mehrere Services etc.):
   ‚Üí auf eine kleine VM mit Docker Compose umziehen.

---

Wenn du wieder am Code bist, k√∂nnen wir dann:

* dein aktuelles `docker-compose.yml` konkret f√ºr OCI anpassen
* und eine kleine Shell-Routine schreiben: ‚Äûpull neues Image + restart Container‚Äú f√ºr Updates.

Gute Frage ‚Äì **das ist der wichtigste Architekturpunkt √ºberhaupt**, bevor du den OCI-Deployment-Flow finalisierst.
Es gibt **3 saubere Wege**, die Daten in der OCI-Container-Deployment-Welt zu handhaben.
Ich zeige sie dir inkl. Empfehlung f√ºr deinen Use-Case.

---

# ‚úÖ **Die drei Wege, wie Daten in den Container kommen k√∂nnen**

## **Option A ‚Äì Daten *in das Image einbauen***

*(einfach ‚Äì aber selten die beste L√∂sung)*

### Wie geht das?

* Du packst die JSON-Dateien in `data/processed/` **direkt ins Git-Repo**.
* Beim Build wandern sie ins Image.
* In OCI brauchst du nichts extra hochladen.

### Vorteil

* Deployment am einfachsten: *pull image ‚Üí run ‚Üí fertig*.

### Nachteil

* Jeder Datenupdate ‚Üí **neues Docker-Image bauen und pushen**.
* Deine Daten w√§ren **nicht mehr getrennt vom Code** (ung√ºnstig f√ºr CI/CD, Security).

### Fazit

F√ºr dich **nicht empfohlen**, weil du Laufzeiten / Runner-Metadaten regelm√§√üig aktualisierst.

---

# üî• **Option B ‚Äì Daten als Volume mounten (empfohlen)**

*(clean, flexibel, OCI-kompatibel)*

Du speicherst die JSON-Daten **au√üerhalb** des Containers und bindest sie beim Deployment ein.

### üëâ Wo liegen die Daten?

Du hast 3 Unteroptionen:

---

## **B1 ‚Äì Lokale Dateien in Container Instance einh√§ngen**

*(einfachster Weg f√ºr OCI Container Instances)*

1. Du erstellst bei der CI eine ‚Äû**File System Mount**‚Äú
2. Beim Start h√§ngst du es in den Container:

```yaml
volumeMounts:
  - mountPath: /app/data/processed
    volumeName: sola-data
volumes:
  - name: sola-data
    source:
      localFileSystem:
        mountPath: /mnt/sola-data
```

3. Auf der CI legst du die JSONs ab in `/mnt/sola-data`
4. Fertig ‚Äì keine Images rebuilden.

### Vorteil

* Daten k√∂nnen unabh√§ngig aktualisiert werden.
* Sehr stabil und ideal f√ºr dein Projekt.

### Nachteil

* Kleine manuelle Pflege: beim Deployment musst du JSONs einmal hinladen.

---

## **B2 ‚Äì Object Storage + Download beim Startup (automatisch)**

*(sehr elegant, CI/CD-ready)*

### Ablauf:

1. Du packst alle JSONs in ein OCI Object-Storage-Bucket, z. B.:
   `sola-history-data/runners.json`, `results.json`, ...
2. Der Container l√§dt beim Start die Daten automatisch herunter:

```dockerfile
ENTRYPOINT ["sh", "-c", "python tools/fetch_data.py && streamlit run app.py"]
```

`fetch_data.py` l√§dt z. B.:

```python
import oci

object_storage = oci.object_storage.ObjectStorageClient(config)
bucket = "sola-history-data"
namespace = "<tenancy-namespace>"

files = ["runners.json", "results.json", "teams.json", ...]

for f in files:
    resp = object_storage.get_object(namespace, bucket, f)
    with open(f"/app/data/processed/{f}", "wb") as out:
        out.write(resp.data.content)
```

### Vorteil

* Fully automated.
* CI/CD kann Daten aktualisieren, ohne Image neu zu bauen.
* Container startet immer mit aktuellen Daten.

### Nachteil

* Ben√∂tigt OCI API Key / Instance Principal.

Dies w√§re die **professionellste L√∂sung**.

---

## **B3 ‚Äì Git Repo der Daten separat klonen und mounten**

*(auch m√∂glich, aber weniger sch√∂n)*

Container zieht die Daten z. B. aus einem privaten GitHub-Repo.

---

# üîí **Option C ‚Äì Persistent Storage: OCI File Storage / Block Volume**

F√ºr Container Instances:

* **Block Volume** oder **File Storage** mounten
* Dort liegen JSONs dauerhaft
* Container liest / schreibt

Ist f√ºr dich erst sinnvoll, wenn du wirklich Daten *persistent* ver√§ndern willst (z. B. Admin-Overrides, Runner-Stammdaten, etc.).

Aktuell nutzt du JSON + Overrides ‚Üí **geht super mit Local File System Mounts.**

---

# ü•á **Empfehlung f√ºr deinen konkreten Use-Case**

Da du:

* JSONs generierst,
* sie als ‚ÄûDatenbank-Ersatz‚Äú nutzt,
* ab und zu neue Daten importierst,
* UND einen einfachen OCI-Deployment-Flow m√∂chtest,

empfehle ich:

---

## ‚≠ê **BEST PRACTICE f√ºr dich: Option B1 (Volume) + sp√§ter Upgrade auf B2**

### **B1 ‚Äì Jetzt sofort: Local Volume f√ºr die Daten**

* Container Image bleibt klein und stabil
* Daten liegen au√üerhalb
* Leicht per SCP oder OCI CLI aktualisierbar

### **B2 ‚Äì Sp√§ter: Automatischer Download aus Object Storage**

* Wenn du CI/CD perfektionieren willst
* Daten-Pipeline = sauber, automatisiert, versionskontrolliert

---

# üîß **Wie laufen Updates in Option B1 konkret?**

1. Neues Excel importieren ‚Üí neue JSONs generieren ‚Üí commit in Git oder lokal halten.
2. Auf OCI:

```bash
scp data/processed/*.json opc@<ci-host>:/mnt/sola-data/
```

3. CI neu starten:

```bash
oci container-instances container restart ...
```

Fertig.

---

# üìù **Wenn du m√∂chtest, kann ich dir Folgendes erzeugen:**

* **fertige OCI Container Instance YAML/CLI-Definition**
* **fetch_data.py** vollst√§ndig
* **angepasstes Dockerfile f√ºr Multi-Stage**
* **CI/CD Workflow**, der:

  * Daten validiert
  * Daten hochl√§dt ins Object Storage
  * Container neu deployt

Sag Bescheid ‚Äì was soll ich als N√§chstes liefern?

Sehr gute (und genau die richtige) Frage üôå
Kurzantwort:

> **Deine CI/CD-Pipeline braucht f√ºr Build & Deploy keine echten SOLA-Daten.**
> Die produktiven Daten leben *au√üerhalb* der Pipeline (Volume / Object Storage etc.) und werden separat gepflegt.

Ich breche das mal sauber auf:

---

## 1. Was macht die CI/CD-Pipeline eigentlich?

Die Pipeline, die wir skizziert haben, hat zwei Aufgaben:

1. **CI (Code-Qualit√§t)**

   * Baut ein venv
   * Installiert `requirements.txt`
   * Optional: f√ºhrt `import_excel.py` aus ‚Äì **nur** wenn im Repo Test-/Sampledaten vorhanden sind
   * Syntax-Check / Tests (`python -m py_compile app.py`)

2. **CD (Image-Build & Push)**

   * Baut dein Docker-Image
   * Push nach Registry (z.B. OCIR)

üëâ **Wichtig:**
Das ist eine **Code-Pipeline**. Sie muss *nicht* mit den produktiven SOLA-Daten laufen, sondern nur beweisen, dass dein Code/Build funktioniert.

---

## 2. Woher kommen die *produktiven* Daten dann?

Die produktiven Daten (deine echten Excel + daraus generierte JSONs) sollten **nicht** ins Git.
Daher trennen wir:

### üîπ A) Code-Pipeline (GitHub Actions)

* Arbeitet mit:

  * Code (`app.py`, `tools/import_excel.py`, `Dockerfile`, etc.)
  * Optional: anonymisierte **Sample-Daten** im Repo (`data/sample/...`), damit `import_excel.py` getestet werden kann
* **Keine** echten Excel (`sola_history.xlsx`, `sola_contacts.xlsx`)

### üîπ B) Daten-Pipeline (manuell oder sp√§ter automatisiert)

Varianten:

#### Variante B1 ‚Äì jetzt sofort (einfach & pragmatisch)

1. **Produktivdaten bleiben lokal bei dir**

   * Du pflegst Excel lokal.
   * Du machst `make import`.
   * Du bekommst `data/processed/*.json`.

2. **Deployment nach OCI:**

   * Du kopierst nur die JSONs auf die Zielumgebung (z.B. `/opt/sola/data/processed` oder `/mnt/sola-data` bei Container Instance).
   * Der Container sieht die JSONs √ºber ein **Volume**:

     * VM: `- /opt/sola/data/processed:/app/data/processed:ro`
     * Container Instance: Local Filesystem Mount ‚Üí `/app/data/processed`

3. Das Image aus CI/CD ist blind gegen√ºber den produktiven Daten ‚Äì es erwartet nur:
   ‚ÄûIn `/app/data/processed` liegen g√ºltige JSONs.‚Äú

‚û°Ô∏è Die CI/CD-Pipeline **braucht** keine echten Daten.
Die Daten werden parallel von dir gepflegt und deployed.

---

#### Variante B2 ‚Äì sp√§ter: Object Storage + Download beim Start

Wenn du es irgendwann ‚Äûrichtig sexy‚Äú machen willst:

* Du hast ein **separates Data-Deployment**:

  * Script / Job, der aus deinen lokalen JSONs ein ZIP macht und in ein OCI Object Storage Bucket l√§dt.
* Im Container:

  * Start-Script l√§dt beim Start die JSONs aus dem Bucket in `/app/data/processed`.

Dann sieht der Flow so aus:

* **Code-Pipeline (GitHub)**:

  * baut/pusht Image
* **Data-Pipeline (lokal oder sp√§ter auch CI)**:

  * l√§dt JSON-Daten ins Bucket
* **Runtime (OCI)**:

  * Container zieht Daten beim Start

Aber das ist f√ºr jetzt schon ‚ÄûPhase 2‚Äú.

---

## 3. Was macht dann `import_excel.py` in der CI?

Du hast zwei M√∂glichkeiten:

### Option 1 ‚Äì Kein produktiver Import in CI

* In der CI **kein** produktiver Excel-Import.

* Der Schritt in der GitHub Action pr√ºft z.B.:

  ```bash
  if [ -f data/raw/sola_history.xlsx ] && [ -f data/raw/sola_contacts.xlsx ]; then
      python tools/import_excel.py
  else
      echo "No Excel input found ‚Äì skipping import step."
  fi
  ```

* ‚Üí In deinem √∂ffentlichen Repo sind die Dateien nicht vorhanden ‚Üí Import wird einfach **√ºbersprungen**.

* CI pr√ºft nur:

  * Builds sauber?
  * Syntax ok?
  * Docker-Image baubar?

### Option 2 ‚Äì Sample-Daten nur f√ºr CI

* Du legst **kleine, anonymisierte** Excel-Dateien in `data/sample/`.
* `import_excel.py` bekommt einen Parameter (z.B. `--sample`), um aus diesen Sample-Files JSON zu bauen.
* CI nutzt nur die Sample-Files, **nie deine echten Daten**.

---

## 4. Empfehlung f√ºr dich (praktisch & minimal)

F√ºr deinen Stand heute:

1. **Public Repo / Haupt-Repo**:

   * Kein `data/raw/` und kein `data/processed/` drin.
   * Optional `data/sample/` mit anonymen Mini-Daten f√ºr Tests.

2. **Produktivdaten-Handling**:

   * Du pflegst Excel lokal.
   * `make import` ‚Üí erzeugt JSONs lokal.
   * JSONs via `scp` oder `rsync` nach OCI (VM oder Container Instance Volume).

3. **CI/CD-Pipeline**:

   * Baut Image **ohne** echte Daten.
   * Macht Syntax-/Build-Checks.
   * Pusht Image nach OCIR.
   * Deployment erwartet nur:
     ‚ÄûDaten liegen per Volume in `/app/data/processed` bereit.‚Äú

Damit ist deine Frage beantwortet:

> **‚ÄûWo nimmt meine CI/CD Pipeline die Daten her?‚Äú**

‚Üí **Gar nicht** ‚Äì sie k√ºmmert sich nur um Code & Images.
Die Daten flie√üen √ºber einen getrennten Weg (Volumes / ggf. sp√§ter Object Storage).

---

Wenn du m√∂chtest, k√∂nnen wir als n√§chsten Schritt:

* ein kleines **Shell-Script** definieren:
  `deploy_data_to_oci.sh`, das:

  * deine `data/processed/*.json` auf eine VM oder in ein Mount-Verzeichnis einer Container Instance kopiert.
* oder einen **Plan f√ºr eine Data-Pipeline** (Phase 2) mit Object Storage skizzieren.

Super, jetzt werden wir ‚ÄûDaten‚Äú offiziell zu einem eigenen Projektteil üçø

Ich schlage dir eine **zweigeteilte Architektur** vor:

* **Code-Pipeline (CI/CD)** ‚Üí baut & deployt nur **Image**
* **Daten-Pipeline** ‚Üí verwaltet **SOLA-Daten** getrennt von Code

Und f√ºr die Daten-Pipeline machen wir einen Plan in **Phasen**, damit du klein starten und sp√§ter ausbauen kannst.

---

## 0. Grundprinzipien f√ºr deine Daten

**Artefakte:**

* **Rohdaten (lokal, nicht Git):**

  * `data/raw/sola_history.xlsx`
  * `data/raw/sola_contacts.xlsx`

* **Verarbeitete Daten (lokal + Server):**

  * `data/processed/runners.json`
  * `data/processed/teams.json`
  * `data/processed/results.json`
  * `data/processed/legs.json`
  * `data/processed/races.json`
  * `data/processed/runners_overrides.json` (wird von der App geschrieben)

* **Schema (im Git):**

  * `data/schema/sola.schema.json`

**Ziel:**

* *App in OCI* liest **immer nur** aus `/app/data/processed/`
* Wie die Daten dort hinkommen, ist Aufgabe der **Daten-Pipeline**

---

## Phase 1 ‚Äì Lokale Datenpflege + manueller Upload

Das ist im Prinzip das, was du heute schon machst ‚Äì nur bewusst als ‚ÄûPipeline‚Äú gedacht.

### 1.1. Lokal: Daten aktualisieren

Workflow lokal:

1. Excel anpassen (neue Jahre, neue L√§ufer, Korrekturen)

2. Import ausf√ºhren:

   ```bash
   make import
   ```

   ‚Üí generiert `data/processed/*.json`

3. Optional: JSON grob checken / kurz die App lokal laufen lassen.

### 1.2. Datenpaket bauen

Damit du einen klaren Schritt hast: ‚ÄûDaten fertig, jetzt Paket‚Äú.

Mach dir z.B. im Makefile ein Ziel:

```makefile
DATA_PACKAGE = data/sola-data-$(shell date +%Y%m%d-%H%M%S).tar.gz

package-data:
	tar czf $(DATA_PACKAGE) -C data/processed .
	@echo "Created data package: $(DATA_PACKAGE)"
```

Ergebnis: `data/sola-data-20251202-203000.tar.gz`

### 1.3. Upload nach OCI (VM oder Filesystem der Container Instance)

**Variante Compute-VM:**

* Zielverzeichnis auf der VM: `/opt/sola/data/processed`

```bash
scp data/processed/*.json opc@<vm-public-ip>:/opt/sola/data/processed/
```

Dein `docker-compose.yml` auf der VM:

```yaml
services:
  sola-history:
    image: eu-zurich-1.ocir.io/<namespace>/sola-history:latest
    volumes:
      - /opt/sola/data/processed:/app/data/processed:ro
    ports:
      - "8501:8501"
    environment:
      - SOLA_APP_PASSWORD=...
```

**Variante Container Instance mit Local Filesystem:**

* Du hast auf der CI ein lokales Filesystem-Mount, z.B. `/mnt/sola-data`
* Container Mount:

  * Host-Pfad: `/mnt/sola-data`
  * Container-Pfad: `/app/data/processed`

Upload:

```bash
scp data/processed/*.json opc@<some-host-or-bastion>:/mnt/sola-data/
```

> Phase 1 = **vollkommen ausreichend**, wenn du 1‚Äì2x pro Jahr aktualisierst.

---

## Phase 2 ‚Äì Daten in OCI Object Storage & ‚ÄûPull beim Start‚Äú

Wenn du das Ganze ‚Äûcloudiger‚Äú machen willst, wird Object Storage dein Datenspeicher.

### 2.1. Bucket-Struktur

* Bucket: `sola-history-data`
* Namespace: dein OCI-Tenancy-Namespace
* Prefixe:

  ```text
  runners.json
  teams.json
  legs.json
  races.json
  results.json
  runners_overrides.json   # optional, wenn du es zentral speichern willst
  meta/version.json        # Metadaten (Zeitstempel, Kommentar, etc.)
  ```

### 2.2. Lokales Upload-Script

Ein kleines Script, das du **auf deinem Laptop** startest, z.B. `tools/upload_data_to_oci.sh`:

```bash
#!/usr/bin/env bash
set -euo pipefail

BUCKET="sola-history-data"
NAMESPACE="<dein-namespace>"
COMPARTMENT_OCID="<compartment-ocid>"

echo "Uploading processed JSON to OCI Object Storage..."

for f in data/processed/*.json; do
  base=$(basename "$f")
  echo "  -> $base"
  oci os object put \
    --bucket-name "$BUCKET" \
    --namespace "$NAMESPACE" \
    --file "$f" \
    --name "$base" \
    --content-type "application/json" \
    --force
done

# Optional: meta/version.json aktualisieren
timestamp=$(date -Iseconds)
tmpfile=$(mktemp)
cat > "$tmpfile" <<EOF
{
  "deployed_at": "$timestamp",
  "source_machine": "$(hostname)",
  "comment": "Manual upload"
}
EOF

oci os object put \
  --bucket-name "$BUCKET" \
  --namespace "$NAMESPACE" \
  --file "$tmpfile" \
  --name "meta/version.json" \
  --content-type "application/json" \
  --force

rm "$tmpfile"

echo "Done."
```

Dann:

```bash
chmod +x tools/upload_data_to_oci.sh
tools/upload_data_to_oci.sh
```

Voraussetzung: Lokale `oci`-CLI + Config.

---

### 2.3. Container l√§dt Daten beim Start

Jetzt wird der Container ‚Äûsmart‚Äú: Beim Start l√§dt er die JSONs aus Object Storage in `/app/data/processed`.

Du brauchst:

* Python-Paket `oci` im Image (`pip install oci`)
* kleines `tools/fetch_data.py`, das:

  * die Umgebung liest: `SOLA_DATA_BUCKET`, `SOLA_DATA_NAMESPACE`
  * mit **Instance Principal** authentifiziert (beste Option bei OCI Container Instance)
  * alle ben√∂tigten Dateien herunterl√§dt

Grob:

```python
# tools/fetch_data.py
import os
import oci
from pathlib import Path

DATA_DIR = Path("/app/data/processed")
FILES = [
    "runners.json",
    "teams.json",
    "legs.json",
    "races.json",
    "results.json",
    "runners_overrides.json",
]

def main():
    bucket = os.environ.get("SOLA_DATA_BUCKET", "sola-history-data")
    namespace = os.environ.get("SOLA_DATA_NAMESPACE")
    if not namespace:
        raise SystemExit("SOLA_DATA_NAMESPACE not set")

    signer = oci.auth.signers.InstancePrincipalsSecurityTokenSigner()
    client = oci.object_storage.ObjectStorageClient(config={}, signer=signer)

    DATA_DIR.mkdir(parents=True, exist_ok=True)

    for name in FILES:
        print(f"Downloading {name} ...")
        obj = client.get_object(namespace, bucket, name)
        (DATA_DIR / name).write_bytes(obj.data.content)

if __name__ == "__main__":
    main()
```

**Dockerfile-Anpassung:**

```dockerfile
# im Builder:
RUN pip install --no-cache-dir -r requirements.txt \
 && pip install --no-cache-dir fpdf oci || true

# im Runtime-Image:
COPY tools ./tools

CMD ["sh", "-c", "python tools/fetch_data.py && streamlit run app.py --server.port=8501 --server.address=0.0.0.0"]
```

**Env-Vars in OCI setzen:**

* `SOLA_DATA_BUCKET=sola-history-data`
* `SOLA_DATA_NAMESPACE=<dein-namespace>`

Dann ist der Ablauf:

1. Du l√§dst JSONs mit `upload_data_to_oci.sh` in den Bucket
2. Du startest / restartest den Container in OCI
3. Beim Start:

   * Container holt die aktuelle Version aus Object Storage
   * Danach startet Streamlit mit frischen Daten

---

## Phase 3 ‚Äì Optional: Daten-Pipeline automatisieren

Wenn du richtig Lust bekommst üòÑ:

* **GitHub Actions ‚Äûdata-only‚Äú Workflow**:

  * L√§uft in einem privaten Repo mit Zugang zu den Excels (oder auf Self-Hosted Runner)
  * F√ºhrt `make import` aus
  * Ruft `tools/upload_data_to_oci.sh` (oder direkt `oci os object put`) auf

* Versionierst dein Dataset z.B. mit Prefixen:

  ```text
  snapshots/2025-05-01/runners.json
  snapshots/2025-05-01/results.json
  latest/runners.json
  latest/results.json
  ```

* Container holt immer aus `latest/`, du kannst im Bucket noch alte Snapshots aufbewahren.

---

## Zusammenfassung in einem Satz

* **Code-Pipeline**: baut Images ohne echte Daten
* **Daten-Pipeline**: erzeugt lokale JSONs aus Excel ‚Üí l√§dt sie nach OCI (Volume oder Object Storage) ‚Üí Container zieht sie beim Start

Wenn du m√∂chtest, kann ich dir als n√§chstes:

* ein konkretes `tools/upload_data_to_oci.sh` + `tools/fetch_data.py` *voll ausformuliert* bauen
* oder eine kleine **ASCII-Architektur√ºbersicht** (Local ‚Üí GitHub ‚Üí OCI Registry ‚Üí OCI Runtime ‚Üí Object Storage).

Sehr gute Stelle f√ºr den n√§chsten Ausbau-Schritt üöÄ
Ich baue dir jetzt **konkret**:

1. `tools/upload_data_to_oci.sh` ‚Äì l√§uft **lokal** und l√§dt `data/processed/*.json` in einen Object-Storage-Bucket
2. `tools/fetch_data.py` ‚Äì l√§uft **im Container** und zieht die JSONs beim Start nach `/app/data/processed`

Du kannst beides sp√§ter 1:1 ins Repo legen.

---

## 1Ô∏è‚É£ `tools/upload_data_to_oci.sh` ‚Äì Upload der JSON-Daten nach OCI Object Storage

**Ziel:**
Von deinem Mac/Notebook aus die generierten JSONs (`data/processed/*.json`) in einen Bucket schieben, z.B. `sola-history-data`.

> Annahmen:
>
> * `oci` CLI ist lokal konfiguriert (`oci setup config` gemacht)
> * du hast schon einen Bucket `sola-history-data` in einem Compartment angelegt

Lege die Datei `tools/upload_data_to_oci.sh` an:

```bash
#!/usr/bin/env bash
#
# Upload all processed JSON files to an OCI Object Storage bucket.
# Intended to be run locally from the repo root or tools/ directory.
#
# Usage:
#   tools/upload_data_to_oci.sh
#
# Optional environment variables:
#   SOLA_DATA_BUCKET     - name of the Object Storage bucket (default: sola-history-data)
#   SOLA_DATA_NAMESPACE  - OCI namespace; if not set, taken from `oci os ns get`
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
PROCESSED_DIR="${REPO_ROOT}/data/processed"

BUCKET_NAME="${SOLA_DATA_BUCKET:-sola-history-data}"

# ------------------------------------------------------------------------------
# Prerequisite checks
# ------------------------------------------------------------------------------

if ! command -v oci >/dev/null 2>&1; then
  echo "ERROR: 'oci' CLI not found. Please install and configure OCI CLI first."
  echo "See: https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm"
  exit 1
fi

if [ ! -d "${PROCESSED_DIR}" ]; then
  echo "ERROR: Processed data directory not found: ${PROCESSED_DIR}"
  echo "Run 'make import' first to generate JSON files."
  exit 1
fi

shopt -s nullglob
JSON_FILES=("${PROCESSED_DIR}"/*.json)
shopt -u nullglob

if [ ${#JSON_FILES[@]} -eq 0 ]; then
  echo "ERROR: No JSON files found in ${PROCESSED_DIR}"
  echo "Run 'make import' first to generate JSON files."
  exit 1
fi

# Determine namespace (if not provided via env)
if [ -n "${SOLA_DATA_NAMESPACE:-}" ]; then
  NAMESPACE="${SOLA_DATA_NAMESPACE}"
else
  echo "Detecting OCI namespace via 'oci os ns get' ..."
  NAMESPACE="$(oci os ns get --query 'data' --raw-output)"
fi

if [ -z "${NAMESPACE}" ]; then
  echo "ERROR: Could not determine OCI Object Storage namespace."
  exit 1
fi

echo "============================================"
echo " Uploading SOLA data to OCI Object Storage"
echo "--------------------------------------------"
echo " Namespace : ${NAMESPACE}"
echo " Bucket    : ${BUCKET_NAME}"
echo " Source    : ${PROCESSED_DIR}"
echo " Files     : ${#JSON_FILES[@]}"
echo "============================================"
echo

# ------------------------------------------------------------------------------
# Upload JSON files
# ------------------------------------------------------------------------------

for f in "${JSON_FILES[@]}"; do
  base="$(basename "${f}")"
  echo "Uploading ${base} ..."
  oci os object put \
    --bucket-name "${BUCKET_NAME}" \
    --namespace "${NAMESPACE}" \
    --file "${f}" \
    --name "${base}" \
    --content-type "application/json" \
    --force \
    >/dev/null
done

# ------------------------------------------------------------------------------
# Write a small version/metadata object
# ------------------------------------------------------------------------------

echo
echo "Writing meta/version.json ..."

TMP_META="$(mktemp)"
TIMESTAMP="$(date -Iseconds)"
HOSTNAME="$(hostname || echo 'unknown-host')"

cat > "${TMP_META}" <<EOF
{
  "deployed_at": "${TIMESTAMP}",
  "source_host": "${HOSTNAME}",
  "processed_dir": "data/processed",
  "comment": "Manual upload of SOLA data"
}
EOF

oci os object put \
  --bucket-name "${BUCKET_NAME}" \
  --namespace "${NAMESPACE}" \
  --file "${TMP_META}" \
  --name "meta/version.json" \
  --content-type "application/json" \
  --force \
  >/dev/null

rm -f "${TMP_META}"

echo
echo "‚úÖ Upload completed."
echo "Bucket:  ${BUCKET_NAME}"
echo "Ns:      ${NAMESPACE}"
```

**Nicht vergessen:**

```bash
chmod +x tools/upload_data_to_oci.sh
```

Typischer Flow dann:

```bash
make import
tools/upload_data_to_oci.sh
```

---

## 2Ô∏è‚É£ `tools/fetch_data.py` ‚Äì Download im Container beim Start

**Ziel:**
Dieser Code l√§uft im Container (oder optional lokal) und zieht die JSONs aus Object Storage nach `/app/data/processed`.

> Annahmen:
>
> * Image enth√§lt das Python-Paket `oci`
> * Im Container sind gesetzt:
>
>   * `SOLA_DATA_BUCKET` (z.B. `sola-history-data`)
>   * **optional** `SOLA_DATA_NAMESPACE` (wenn nicht gesetzt, wird es via API geholt)
> * Auth im Container: **Instance Principals** (Container Instance) oder `config.from_file()` f√ºr lokalen Test

### 2.1 Datei `tools/fetch_data.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fetch processed SOLA data JSON files from OCI Object Storage and write them
to data/processed/ so that the Streamlit app can consume them.

Intended usage:
  - run in OCI (Container Instance or VM) with Instance Principals
  - optionally: run locally with an OCI CLI config (~/.oci/config)

Environment variables:
  SOLA_DATA_BUCKET     - name of the Object Storage bucket (default: sola-history-data)
  SOLA_DATA_NAMESPACE  - namespace; if not set, it is fetched via get_namespace()
"""

import os
import sys
from pathlib import Path

import oci


# Files we expect in the bucket
FILES = [
    "runners.json",
    "teams.json",
    "legs.json",
    "races.json",
    "results.json",
    "runners_overrides.json",  # optional, if you decide to keep overrides in Object Storage
]


def get_object_storage_client():
    """
    Try to create an ObjectStorageClient.

    Priority:
    1. Instance Principals (OCI runtime, e.g. Container Instance)
    2. Local config via ~/.oci/config (profile: DEFAULT)
    """
    # Try instance principals
    try:
        signer = oci.auth.signers.InstancePrincipalsSecurityTokenSigner()
        # region is taken from instance metadata; the SDK usually picks that up
        cfg = {"region": signer.region}
        print(f"[fetch_data] Using Instance Principals (region={signer.region})")
        return oci.object_storage.ObjectStorageClient(config=cfg, signer=signer)
    except Exception as e:
        print(f"[fetch_data] Instance Principals not available ({e}), trying config file...")

    # Fallback: local config (~/.oci/config)
    try:
        cfg = oci.config.from_file()
        print(f"[fetch_data] Using config from ~/.oci/config (region={cfg.get('region')})")
        return oci.object_storage.ObjectStorageClient(config=cfg)
    except Exception as e:
        print(f"[fetch_data] ERROR: Could not create ObjectStorageClient via config file: {e}")
        raise


def main() -> int:
    base_dir = Path(__file__).resolve().parents[1]  # /app (assuming tools/ inside repo root)
    data_dir = base_dir / "data" / "processed"
    data_dir.mkdir(parents=True, exist_ok=True)

    bucket_name = os.environ.get("SOLA_DATA_BUCKET", "sola-history-data")

    client = get_object_storage_client()

    # Determine namespace
    namespace = os.environ.get("SOLA_DATA_NAMESPACE")
    if namespace:
        print(f"[fetch_data] Using namespace from env: {namespace}")
    else:
        print("[fetch_data] No SOLA_DATA_NAMESPACE set, calling get_namespace() ...")
        ns_resp = client.get_namespace()
        namespace = ns_resp.data
        print(f"[fetch_data] Discovered namespace: {namespace}")

    print("============================================")
    print(" Fetching SOLA JSON data from Object Storage")
    print("--------------------------------------------")
    print(f" Namespace : {namespace}")
    print(f" Bucket    : {bucket_name}")
    print(f" Target    : {data_dir}")
    print("============================================")

    for name in FILES:
        try:
            print(f"[fetch_data] Downloading {name} ...")
            obj = client.get_object(namespace, bucket_name, name)
            target = data_dir / name
            target.write_bytes(obj.data.content)
            print(f"[fetch_data]   -> wrote {target}")
        except oci.exceptions.ServiceError as se:
            if se.status == 404:
                print(f"[fetch_data] WARNING: Object not found: {name} (status=404)")
            else:
                print(f"[fetch_data] ERROR: Could not fetch {name}: {se}", file=sys.stderr)
        except Exception as e:
            print(f"[fetch_data] ERROR: Unexpected error fetching {name}: {e}", file=sys.stderr)

    print("[fetch_data] Done.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

---

## 3Ô∏è‚É£ Dockerfile-Integration (kurze Erinnerung)

Damit `fetch_data.py` im Container funktioniert, musst du:

1. **`oci` ins Image installieren**
   ‚Üí `requirements.txt` erg√§nzen oder direkt im Dockerfile:

```dockerfile
# im Builder-Stage:
RUN pip install --upgrade pip \
 && pip install --no-cache-dir -r requirements.txt \
 && pip install --no-cache-dir fpdf oci || true
```

2. **`tools/` ins Image kopieren**

In deinem bestehenden Dockerfile (Runtime-Stage):

```dockerfile
WORKDIR /app

# libs aus builder
COPY --from=builder /usr/local/lib/python3.11 /usr/local/lib/python3.11
COPY --from=builder /usr/local/bin /usr/local/bin

# App-Code
COPY app.py ./app.py
COPY data/schema ./data/schema
COPY tools ./tools

RUN mkdir -p data/processed

EXPOSE 8501

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

CMD ["sh", "-c", "python tools/fetch_data.py && streamlit run app.py --server.port=8501 --server.address=0.0.0.0"]
```

3. **Env-Variablen beim Deployment setzen (OCI)**

Bei Container Instance oder Compose-File:

* `SOLA_DATA_BUCKET=sola-history-data`
* (optional) `SOLA_DATA_NAMESPACE=<dein-namespace>` ‚Äì kann auch automatisch herausgefunden werden

---

## 4Ô∏è‚É£ Typischer Gesamt-Flow

Lokal:

```bash
# 1. Daten aus Excel neu generieren
make import

# 2. JSONs in Object Storage hochladen
tools/upload_data_to_oci.sh

# 3. Code √§ndern, committen, Tag setzen ‚Üí CI/CD baut/pusht Image
#    (Workflow hatten wir ja vorhin)
```

OCI:

* Container neu starten:

  * Beim Start ruft er `fetch_data.py` auf
  * Holt die JSONs aus dem Bucket nach `/app/data/processed`
  * Startet Streamlit mit aktuellen Daten

---

Wenn du m√∂chtest, k√∂nnen wir als n√§chstes:

* dein Dockerfile genau mit `fetch_data.py` & `oci` zusammenf√ºhren
* oder eine kleine ASCII-Zeichnung/√úbersicht machen, wie **Excel ‚Üí JSON ‚Üí Object Storage ‚Üí Container** zusammenh√§ngt.

Alles klar, dann machen wir jetzt die ‚ÄûBig Picture‚Äú-√úbersicht ‚Äì so, dass du sie auch sp√§ter in eine Doku oder Folien √ºbernehmen kannst üöÄ

---

## Gesamtarchitektur ‚Äì Sola History (Code + Daten)

Ich teile es in **zwei Fl√ºsse**:

1. **Datenfluss**: Excel ‚Üí JSON ‚Üí Object Storage ‚Üí Container
2. **Codefluss**: GitHub ‚Üí CI/CD ‚Üí OCIR ‚Üí Container

Am Ende treffen sich beide im Container in OCI.

---

## 1Ô∏è‚É£ Datenfluss ‚Äì von Excel bis in den Container

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Dein Laptop        ‚îÇ
‚îÇ  (lokal)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 1) Excel pflegen
         ‚îÇ    - data/raw/sola_history.xlsx
         ‚îÇ    - data/raw/sola_contacts.xlsx
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ tools/import_excel.py          ‚îÇ
‚îÇ  - liest Excel                 ‚îÇ
‚îÇ  - normalisiert / rechnet um   ‚îÇ
‚îÇ  - schreibt JSONs nach         ‚îÇ
‚îÇ    data/processed/*.json       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 2) JSONs stehen bereit
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ tools/upload_data_to_oci.sh    ‚îÇ
‚îÇ  - nutzt OCI CLI               ‚îÇ
‚îÇ  - l√§dt alle JSONs nach        ‚îÇ
‚îÇ    Object Storage:             ‚îÇ
‚îÇ    Bucket: sola-history-data   ‚îÇ
‚îÇ    (z.B. runners.json, ...)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 3) JSONs liegen nun zentral
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OCI Object Storage                      ‚îÇ
‚îÇ Bucket: sola-history-data               ‚îÇ
‚îÇ  - runners.json                         ‚îÇ
‚îÇ  - teams.json                           ‚îÇ
‚îÇ  - races.json                           ‚îÇ
‚îÇ  - legs.json                            ‚îÇ
‚îÇ  - results.json                         ‚îÇ
‚îÇ  - meta/version.json (Metadaten)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Im **Container** l√§uft dann:

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Container (OCI)               ‚îÇ
‚îÇ  /app                          ‚îÇ
‚îÇ                                ‚îÇ
‚îÇ  tools/fetch_data.py           ‚îÇ
‚îÇ   - beim Start ausgef√ºhrt      ‚îÇ
‚îÇ   - holt JSONs aus             ‚îÇ
‚îÇ     Bucket sola-history-data   ‚îÇ
‚îÇ   - schreibt nach              ‚îÇ
‚îÇ     /app/data/processed        ‚îÇ
‚îÇ                                ‚îÇ
‚îÇ  app.py (Streamlit)            ‚îÇ
‚îÇ   - liest nur aus              ‚îÇ
‚îÇ     data/processed/*.json      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Merke:**
Die App kennt nur `data/processed`.
Woher die Daten dorthin kommen, ist Aufgabe von `fetch_data.py` (im Container) und `upload_data_to_oci.sh` (bei dir lokal).

---

## 2Ô∏è‚É£ Codefluss ‚Äì von GitHub bis zum laufenden Container

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Github Repo         ‚îÇ
‚îÇ  - app.py            ‚îÇ
‚îÇ  - tools/*.py/.sh    ‚îÇ
‚îÇ  - Dockerfile        ‚îÇ
‚îÇ  - Makefile          ‚îÇ
‚îÇ  - data/schema/*     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 1) Commit / Push
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ GitHub Actions (CI/CD)                  ‚îÇ
‚îÇ  - baut Python-venv                     ‚îÇ
‚îÇ  - installiert requirements.txt         ‚îÇ
‚îÇ  - optional: Tests / Syntaxcheck        ‚îÇ
‚îÇ  - baut Docker-Image                    ‚îÇ
‚îÇ  - pusht Image nach Registry            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 2) Neues Image
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OCI Container Registry (OCIR)          ‚îÇ
‚îÇ  z.B. eu-zurich-1.ocir.io/‚Ä¶/sola-history‚îÇ
‚îÇ  - Tags: v0.1.0, latest, ‚Ä¶             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 3) Deployment
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Compute VM / Container Instance         ‚îÇ
‚îÇ  - zieht Image aus OCIR                 ‚îÇ
‚îÇ  - startet Container mit Env-Vars:      ‚îÇ
‚îÇ      SOLA_APP_PASSWORD=...              ‚îÇ
‚îÇ      SOLA_DATA_BUCKET=sola-history-data ‚îÇ
‚îÇ      SOLA_DATA_NAMESPACE=... (optional) ‚îÇ
‚îÇ  - Container ruft:                      ‚îÇ
‚îÇ      python tools/fetch_data.py         ‚îÇ
‚îÇ      streamlit run app.py               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3Ô∏è‚É£ Zusammenspiel ‚Äì in einem Bild

Einmal alles zusammen:

```text
          LOKAL (bei dir)                            OCI (Cloud)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 Excel-Dateien                           Object Storage (Bucket)
  - sola_history.xlsx                      - runners.json
  - sola_contacts.xlsx                     - teams.json
        ‚îÇ                                   - results.json
        ‚îÇ                                   - ...
        ‚ñº
 tools/import_excel.py
  ‚Üí data/processed/*.json
        ‚îÇ
        ‚îÇ tools/upload_data_to_oci.sh
        ‚ñº
   OCI Object Storage  ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñ≤                                            ‚îÇ
        ‚îÇ fetch_data.py                              ‚îÇ
        ‚îÇ                                            ‚îÇ
Container Image (Code)                       Compute/CI zieht Image
  - aus OCIR                                  - Docker/Container Instance
  - via CI/CD                                 - Env: SOLA_APP_PASSWORD, ...
        ‚îÇ                                     - Start: fetch_data.py ‚Üí app.py
        ‚ñº
  Laufende App (Streamlit)
  - liest nur data/processed/*.json
  - zeigt UI, Stats, Planung
```

---

Wenn du das so ungef√§hr im Kopf hast, ist alles andere (Dockerfile, oci-Config, CI-Details) ‚Äûnur noch Umsetzung‚Äú.

Wenn du magst, k√∂nnen wir als n√§chstes:

* einen kleinen Abschnitt f√ºr deine `doc/README.md` formulieren (‚ÄûArchitecture Overview‚Äú)
* oder deine bestehenden Docs (Root-README, `doc/ci_cd.md`) um diese Architektur erg√§nzen ‚Äì dann hast du das sauber dokumentiert, bevor du weiter am Code schraubst.

Sehr gut, dann machen wir das Dockerfile jetzt ‚Äûrichtig‚Äú ‚Äì schlank, multi-stage, ohne Secrets, mit `fetch_data.py` integriert ‚úÖ

Ich gehe davon aus:

* `app.py` liegt im Repo-Root
* `tools/fetch_data.py` existiert wie von uns gebaut
* `data/schema/` existiert
* `data/processed/` wird **zur Laufzeit** gef√ºllt (nicht ins Image kopiert)
* Python-Abh√§ngigkeiten stehen in `requirements.txt`

Hier das komplette Dockerfile, das du 1:1 √ºbernehmen kannst:

```dockerfile
# ============================================================
# Stage 1: Builder
#  - installiert Python-Abh√§ngigkeiten
# ============================================================
FROM python:3.11-slim AS builder

# Verzeichnis setzen
WORKDIR /app

# System-Pakete (nur was wir wirklich brauchen)
RUN apt-get update && apt-get install -y --no-install-recommends \
    tzdata \
 && rm -rf /var/lib/apt/lists/*

# Requirements ins Image kopieren
COPY requirements.txt .

# Python-Abh√§ngigkeiten installieren
# - fpdf: f√ºr PDF-Export
# - oci: f√ºr Object Storage Zugriff
RUN pip install --upgrade pip \
 && pip install --no-cache-dir -r requirements.txt \
 && pip install --no-cache-dir fpdf oci || true


# ============================================================
# Stage 2: Runtime
#  - nur das N√∂tigste aus dem Builder √ºbernehmen
# ============================================================
FROM python:3.11-slim AS runtime

WORKDIR /app

# Zeitzone-Paket (falls du mit Zeiten arbeitest)
RUN apt-get update && apt-get install -y --no-install-recommends \
    tzdata \
 && rm -rf /var/lib/apt/lists/*

# Python-Runtime + installierte Pakete aus dem Builder √ºbernehmen
COPY --from=builder /usr/local/lib/python3.11 /usr/local/lib/python3.11
COPY --from=builder /usr/local/bin /usr/local/bin

# App-Code kopieren
COPY app.py ./app.py
COPY tools ./tools
COPY data/schema ./data/schema

# Laufzeit-Verzeichnis f√ºr Daten (wird per fetch_data.py/Object Storage gef√ºllt
# oder als Volume gemountet)
RUN mkdir -p data/processed

# Environment-Defaults (keine Secrets!)
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Port f√ºr Streamlit
EXPOSE 8501

# Start-Kommando:
# 1) Daten aus Object Storage holen (tools/fetch_data.py)
# 2) Streamlit-App starten
CMD ["sh", "-c", "python tools/fetch_data.py && streamlit run app.py --server.port=8501 --server.address=0.0.0.0"]
```

---

### Wie passt das in deinen Flow?

**Build lokal:**

```bash
docker build -t sola-history:latest .
```

**Run lokal mit Daten aus Volume (ohne Object Storage):**

```bash
docker run --rm -p 8501:8501 \
  -e SOLA_APP_PASSWORD=sola \
  -v $(pwd)/data/processed:/app/data/processed:ro \
  sola-history:latest
```

**Run in OCI mit Object Storage:**

* Env vars setzen:

  * `SOLA_APP_PASSWORD=‚Ä¶`
  * `SOLA_DATA_BUCKET=sola-history-data`
  * optional `SOLA_DATA_NAMESPACE=<dein-namespace>`
    (sonst ermittelt `fetch_data.py` das selbst)

* Container Instance / Compose-Definition zeigt einfach auf dieses Image ‚Äì `fetch_data.py` holt die JSONs beim Start.

---

Wenn du mir sp√§ter noch dein aktuelles `docker-compose.yml` zeigst, kann ich es dir auch direkt auf dieses Dockerfile + OCI-Deployment trimmen (lokal & remote kompatibel).

Perfekt ‚Äî dann definieren wir jetzt **die saubere, professionelle Repo-Struktur** f√ºr **zwei getrennte Repositories**:

1Ô∏è‚É£ **sola-history-app** ‚Üí enth√§lt *nur Code*, kein einziges personenbezogenes Datum
2Ô∏è‚É£ **sola-history-data** ‚Üí enth√§lt *Datenpipelines*, aber **keine Rohdaten**, sondern nur Tools f√ºr Daten-Upload/Download

‚û°Ô∏è Die echten Rohdaten (`sola_contacts.xlsx`, `sola_history.xlsx`, Ergebnisse etc.) bleiben **lokal oder in OCI Object Storage**, aber **niemals im Git**.

---

# üìÅ **Repository 1: sola-history-app**

üîπ *enth√§lt die App, das Dockerfile, die Import-Tools & die Daten-Schemata ‚Äî aber keine echten Daten*

```
sola-history-app/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ schema/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sola.schema.json
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Wird zur Laufzeit gef√ºllt!
‚îÇ       ‚îú‚îÄ‚îÄ runners.json        # NICHT im Repo!
‚îÇ       ‚îú‚îÄ‚îÄ teams.json
‚îÇ       ‚îú‚îÄ‚îÄ results.json
‚îÇ       ‚îú‚îÄ‚îÄ legs.json
‚îÇ       ‚îú‚îÄ‚îÄ races.json
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ import_excel.py         # Parser (lokal genutzt)
‚îÇ   ‚îú‚îÄ‚îÄ fetch_data.py           # Holt JSONs aus OCI
‚îÇ   ‚îú‚îÄ‚îÄ upload_data_to_oci.sh   # Upload Script (optional)
‚îÇ   ‚îú‚îÄ‚îÄ test.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îî‚îÄ‚îÄ ci/
    ‚îú‚îÄ‚îÄ build.yml               # GitHub Actions ‚Üí Docker Build & Push
    ‚îî‚îÄ‚îÄ security.yml            # Dependabot, Linting, Security Checks
```

### üîí Was geht *NICHT* in dieses Repo?

‚ùå `sola_history.xlsx`
‚ùå `sola_contacts.xlsx`
‚ùå irgendeine JSON-Datei mit Personen oder Laufdaten
‚ùå Secrets (OCI Keys, Passw√∂rter)

**‚Üí Nur Tools & Schemas. Keine echten Daten.**

---

# üìÅ **Repository 2: sola-history-data**

üîπ *dient als Datenverwaltung, Upload-Tools, Validierung und Data Governance*

```
sola-history-data/
‚îú‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ raw/                          # Rohdaten (NIE ins Repo!)
‚îÇ   ‚îú‚îÄ‚îÄ sola_history.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ sola_contacts.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ previous_years/
‚îÇ
‚îú‚îÄ‚îÄ processed/                    # Output nach import_excel.py
‚îÇ   ‚îú‚îÄ‚îÄ runners.json
‚îÇ   ‚îú‚îÄ‚îÄ teams.json
‚îÇ   ‚îú‚îÄ‚îÄ results.json
‚îÇ   ‚îú‚îÄ‚îÄ legs.json
‚îÇ   ‚îú‚îÄ‚îÄ races.json
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ import_excel.py          # identisch wie in App-Repo
‚îÇ   ‚îú‚îÄ‚îÄ validate_schema.py       # optional JSON Validator
‚îÇ   ‚îú‚îÄ‚îÄ upload_data_to_oci.sh    # Daten nach OCI pushen
‚îÇ   ‚îî‚îÄ‚îÄ diff_data.py             # Vergleicht alte/neue Daten
‚îÇ
‚îî‚îÄ‚îÄ ci/
    ‚îú‚îÄ‚îÄ validate.yml             # Check Excel, Check JSON Schema
    ‚îî‚îÄ‚îÄ publish.yml              # Publish processed JSONs to OCI bucket
```

üß† **Wichtig:**
Dieses Repo ist **PRIVATE ONLY** ‚Äì aber auch hier *keine personenbezogenen Rohdaten ins Git*.

Die Rohdaten liegen lokal oder in OCI, und werden durch `upload_data_to_oci.sh` automatisiert ins Bucket geschrieben.

---

# üéØ Zweck der Trennung

| Bereich                      | sola-history-app | sola-history-data |
| ---------------------------- | ---------------- | ----------------- |
| App-Code                     | ‚úîÔ∏è               | ‚ùå                 |
| Dockerfile                   | ‚úîÔ∏è               | ‚ùå                 |
| Streamlit                    | ‚úîÔ∏è               | ‚ùå                 |
| Daten-Import                 | ‚úîÔ∏è (Tools)       | ‚úîÔ∏è                |
| JSON-Schema                  | ‚úîÔ∏è               | ‚úîÔ∏è                |
| Personen-/Laufdaten JSON     | ‚ùå                | ‚úîÔ∏è                |
| Rohdaten Excel               | ‚ùå                | ‚ùå (nur lokal)     |
| CI/CD ‚Üí App Deployment       | ‚úîÔ∏è               | ‚ùå                 |
| CI/CD ‚Üí Data Upload nach OCI | ‚ùå                | ‚úîÔ∏è                |

---

# üöõ Datenflow (End-to-End)

### **Local ‚Üí Data Repo ‚Üí OCI ‚Üí App Repo ‚Üí Container ‚Üí Runtime**

```
Excel ‚Üí import_excel.py ‚Üí processed JSON ‚Üí upload_data_to_oci.sh
                                          ‚Üì
                                 OCI Object Storage (Bucket)
                                          ‚Üì
                                sola-history-app Container
                                 runs fetch_data.py on startup
                                          ‚Üì
                                   /app/data/processed/*
                                 Streamlit UI uses JSON
```

---

# üß© CI/CD Empfehlungen

### **sola-history-app CI/CD**

* Build Docker Image (GitHub Actions)
* Push to GitHub Container Registry (GHCR)
* Optional: Push to OCI Registry (`iad.ocir.io/...`)
* Trigger deployment auf OCI:

  * Container Instance
  * Functions
  * Kubernetes (OKE)
  * Container Apps

### **sola-history-data CI/CD**

* Validate Excel (Header, Zeitformate, Runner IDs)
* Generate JSON using import_excel.py
* Validate JSON against schema
* Upload JSON ‚Üí OCI Object Storage

---

# üß± Was muss dokumentiert werden?

### In sola-history-app/README.md

* Run local
* Run via compose
* Build Docker
* Start in OCI
* Data loading (fetch_data.py)

### In sola-history-data/README.md

* Wie Excel strukturiert sein muss
* Import Workflow
* JSON Output Beschreibung (fields)
* Upload nach OCI
* Governances (keine Rohdaten im Repo)

---

# ‚úîÔ∏è Bereit f√ºr den n√§chsten Schritt

Wenn du m√∂chtest, kann ich jetzt f√ºr dich erzeugen:

### ‚úÖ Vollst√§ndige GitHub READMEs (beide Repos)

### ‚úÖ GitHub Actions CI/CD Workflows

### ‚úÖ Terraform f√ºr OCI deployment

### ‚úÖ Daten-Governance-Beschreibung

### ‚úÖ Branching- und Release-Konzept

Sag mir einfach, womit wir weitermachen wollen.


Alles klar ‚Äî hier kommt **Teil 1/2** der Lieferung:
‚û°Ô∏è **Komplette, einsatzbereite READMEs f√ºr beide Repos**
‚û°Ô∏è **Komplette GitHub Actions Workflows f√ºr Build/Deploy & Data Pipeline**

**Teil 2** (Terraform, Governance, Branching, Release-Konzept) sende ich direkt danach.

---

# ‚úÖ **1. README f√ºr Repo: `sola-history-app`**

(Datei: `README.md`)

---

# üèÉ‚Äç‚ôÇÔ∏è **SOLA History ‚Äì App Repository**

Interne Analytics- & Planungsl√∂sung f√ºr Accenture/Trivadis SOLA-L√§ufe

Dieses Repository enth√§lt **nur die Anwendung** (Streamlit App), Dockerfiles, CI/CD und Tools f√ºr den Import der verarbeiteten JSON-Dateien.
**Wichtig:** Hier liegen **keine personenbezogenen Rohdaten** und auch **keine gefertigten JSONs** im Git.

---

# üìÅ Repository Structure

```
sola-history-app/
‚îú‚îÄ‚îÄ app.py                     # Main Streamlit Application
‚îú‚îÄ‚îÄ Dockerfile                 # Multi-stage OCI-ready build
‚îú‚îÄ‚îÄ docker-compose.yml         # Local dev runner
‚îú‚îÄ‚îÄ Makefile                   # Local build/test automation
‚îú‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ schema/                # JSON schema definitions
‚îÇ   ‚îÇ    ‚îî‚îÄ‚îÄ sola.schema.json
‚îÇ   ‚îî‚îÄ‚îÄ processed/             # (Filled at runtime; NOT in Git)
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ import_excel.py        # Parser (local-only)
‚îÇ   ‚îú‚îÄ‚îÄ fetch_data.py          # Loads data from OCI bucket at app startup
‚îÇ   ‚îú‚îÄ‚îÄ upload_data_to_oci.sh  # CI tool for deployments
‚îÇ   ‚îî‚îÄ‚îÄ test.py
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îú‚îÄ‚îÄ build.yml          # Docker Build & Push
        ‚îî‚îÄ‚îÄ lint.yml           # Optional: Code quality
```

---

# üöÄ Running locally

### 1) Install dependencies

```bash
make install
```

### 2) Import processed JSONs

(Nur wenn du lokal Excel importieren willst)

```bash
make import
```

### 3) Start Streamlit

```bash
make run
```

---

# üê≥ Running via Docker Compose

```bash
docker compose up --build
```

Die App l√§uft dann unter:
‚û°Ô∏è [http://localhost:8501](http://localhost:8501)

---

# üì¶ Docker Build (Multi-Stage, Slim)

```bash
docker build -t sola-history:latest .
```

Das Image ist ~200‚Äì250 MB gro√ü dank Multi-Stage & Slim-Base.

---

# üîê Handling Data (safe workflow)

Die App l√§dt beim Start √ºber `tools/fetch_data.py` alle JSONs automatisch:

* `runners.json`
* `teams.json`
* `results.json`
* `races.json`
* `legs.json`

‚Üí aus **OCI Object Storage**

Die Daten liegen **nicht im Container-Image**, sondern werden **beim Start nachgeladen**.

---

# üõ† CI/CD (GitHub Actions)

Dieses Repo erzeugt:

* Docker Image ‚Üí **GHCR**
* Optional: Push in OCI Registry
* Optional: Deployment (Container Instance, OKE oder Container Apps)

Workflows liegen unter `.github/workflows/`.

---

# üîó Required environment variables (for deployment)

| Variable               | Description                  |
| ---------------------- | ---------------------------- |
| `OCI_BUCKET_NAMESPACE` | OCI namespace                |
| `OCI_BUCKET_NAME`      | Bucket name containing JSONs |
| `OCI_BUCKET_REGION`    | Region                       |
| `OCI_BUCKET_URL`       | Prebuilt HTTPS URL           |
| `SOLA_APP_PASSWORD`    | App login                    |

---

# ‚úîÔ∏è Recommended Setup

* Dieses App-Repo bleibt **√∂ffentlich m√∂glich**, aber ohne Daten.
* Alle personenbezogenen Daten kommen **aus dem Data-Repo** oder OCI-Bucket.
* Deployment in OCI basiert auf CI/CD Workflow.

---

# üéØ End of README for sola-history-app

---

# ‚úÖ **2. README f√ºr Repo: `sola-history-data`**

(Datei: `README.md`)

---

# üóÇÔ∏è SOLA History ‚Äì Data Repository

Dieses Repository verwaltet **alle Datenprozesse**:

* Rohdaten (werden **nicht eingecheckt**)
* Import der Excel-Dateien
* Generieren der JSON-Ausgabedaten
* Validieren per JSON-Schema
* Upload nach OCI Object Storage
* Automatisierte Data-Pipeline (CI/CD)

---

# üìÅ Repository Structure

```
sola-history-data/
‚îú‚îÄ‚îÄ raw/                      # NEVER in Git
‚îÇ   ‚îú‚îÄ‚îÄ sola_history.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ sola_contacts.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ previous_years/
‚îÇ
‚îú‚îÄ‚îÄ processed/                # JSON Outputs (generated)
‚îÇ   ‚îú‚îÄ‚îÄ runners.json
‚îÇ   ‚îú‚îÄ‚îÄ results.json
‚îÇ   ‚îú‚îÄ‚îÄ teams.json
‚îÇ   ‚îú‚îÄ‚îÄ races.json
‚îÇ   ‚îî‚îÄ‚îÄ legs.json
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ import_excel.py       # Build JSONs from Excel
‚îÇ   ‚îú‚îÄ‚îÄ validate_schema.py    # Ensure data matches schema
‚îÇ   ‚îú‚îÄ‚îÄ upload_data_to_oci.sh # Upload processed JSON ‚Üí OCI
‚îÇ   ‚îú‚îÄ‚îÄ diff_data.py          # Compare old/new output
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îú‚îÄ‚îÄ validate.yml      # Validate Excel/JSON
        ‚îî‚îÄ‚îÄ publish.yml       # Upload JSONs to OCI
```

---

# üöÄ Workflow

## Schritt 1: Rohdaten vorbereiten

Die Excel-Dateien liegen lokal in:

```
raw/sola_history.xlsx
raw/sola_contacts.xlsx
```

‚ö†Ô∏è **Diese Dateien d√ºrfen NICHT ins Git!**

---

## Schritt 2: JSON generieren

```bash
python tools/import_excel.py
```

Output landet in `processed/`.

---

## Schritt 3: Daten validieren (Schema)

```bash
python tools/validate_schema.py
```

---

## Schritt 4: Upload nach OCI

```bash
tools/upload_data_to_oci.sh processed/*.json
```

Dies aktualisiert die Daten, die das App-Repo konsumiert.

---

# üîê OCI Requirements

* OCI Tenancy OCID
* User OCID
* API Key
* Bucket Name
* Namespace
* Region

Alle Werte m√ºssen als GitHub Secrets gespeichert werden:

| Secret             | Description            |
| ------------------ | ---------------------- |
| `OCI_USER_OCID`    | API user               |
| `OCI_TENANCY_OCID` | Tenancy                |
| `OCI_FINGERPRINT`  | Public key fingerprint |
| `OCI_PRIVATE_KEY`  | PEM private key        |
| `OCI_REGION`       | Region                 |
| `OCI_BUCKET`       | Data bucket            |

---

# ü§ñ CI/CD Pipeline

## validate.yml

* pr√ºft Excel Struktur
* pr√ºft Schema
* pr√ºft Python-Code
* erzeugt Artefakte

## publish.yml

* f√ºhrt Import durch
* erzeugt JSONs
* validated JSON
* l√§dt JSONs nach OCI hoch

---

# üéØ End of README for sola-history-data

---

# ‚úÖ **3. GitHub Actions Workflow f√ºr App-Repo**

### Datei: `.github/workflows/build.yml`

```yaml
name: Build & Publish App

on:
  push:
    branches: ["main"]
  pull_request:

permissions:
  contents: read
  packages: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build Docker Image
        run: |
          docker build -t ghcr.io/${{ github.repository }}:latest .

      - name: Push Docker Image
        run: |
          docker push ghcr.io/${{ github.repository }}:latest
```

(Optional: OCI Registry Push kann erg√§nzt werden.)

---

# ‚úÖ **4. GitHub Actions Workflow f√ºr Data-Repo**

### Datei: `.github/workflows/publish.yml`

```yaml
name: Publish Processed Data

on:
  workflow_dispatch:
  push:
    branches: ["main"]

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Data Import
        run: |
          python tools/import_excel.py

      - name: Validate JSON Schema
        run: |
          python tools/validate_schema.py

      - name: Upload JSON to OCI
        env:
          OCI_TENANCY_OCID: ${{ secrets.OCI_TENANCY_OCID }}
          OCI_USER_OCID: ${{ secrets.OCI_USER_OCID }}
          OCI_FINGERPRINT: ${{ secrets.OCI_FINGERPRINT }}
          OCI_PRIVATE_KEY: ${{ secrets.OCI_PRIVATE_KEY }}
          OCI_REGION: ${{ secrets.OCI_REGION }}
          OCI_BUCKET: ${{ secrets.OCI_BUCKET }}
        run: |
          bash tools/upload_data_to_oci.sh processed/*.json
```

---

# üéâ **Bereit f√ºr Teil 2?**

Ich liefere dir jetzt:

### üìå Terraform-Deployment-Draft (Container Instance + Bucket Zugriff)

### üìå Security & Governance Konzept

### üìå Branching/Release-Konzept

### üìå √úbersicht √ºber Verantwortlichkeiten & Data Ownership

Sobald du ready bist:
üëâ **‚ÄûWeiter mit Teil 2‚Äú**


Sehr gute Zwischenfrage ‚Äì das Nginx-Thema passt perfekt in Teil 2 rein üòÑ
Ich packe alles strukturiert:

1. Einfacher **Nginx Reverse Proxy mit SSL + Let‚Äôs Encrypt + Basic Auth** (VM + Docker Compose)
2. **Terraform-Draft** f√ºr OCI (VM + VCN + Security)
3. **Security & Data-Governance-Skizze**
4. **Branching- & Release-Konzept** (App-Repo & Data-Repo)

---

## 1Ô∏è‚É£ Nginx Reverse Proxy + SSL + Basic Auth (einfach mit Docker Compose)

### Zielbild

* Eine kleine OCI-VM (Oracle Linux / Ubuntu)
* Darauf l√§uft per `docker-compose`:

  * `proxy` (nginx, Termination von HTTPS, Basic Auth)
  * `certbot` (holt/erneuert Let‚Äôs-Encrypt-Zertifikate)
  * `sola-history` (deine Streamlit-App, nur intern erreichbar)

### a) Beispiel `docker-compose.yml` auf der VM

```yaml
version: "3.9"

services:
  sola-history:
    image: ghcr.io/<dein-github-user>/sola-history-app:latest
    container_name: sola-history
    restart: unless-stopped
    environment:
      - SOLA_APP_PASSWORD=${SOLA_APP_PASSWORD}
      - SOLA_DATA_BUCKET=sola-history-data
      - SOLA_DATA_NAMESPACE=<dein-namespace>
    expose:
      - "8501"
    networks:
      - backend

  proxy:
    image: nginx:alpine
    container_name: sola-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/htpasswd:/etc/nginx/htpasswd:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
    networks:
      - backend

  # certbot wird "on demand" gestartet (nicht dauerhaft)
  certbot:
    image: certbot/certbot
    container_name: sola-certbot
    volumes:
      - /etc/letsencrypt:/etc/letsencrypt
      - ./nginx/conf.d:/etc/nginx/conf.d
    entrypoint: /bin/sh
    command: "-c 'sleep infinity'"

networks:
  backend:
    driver: bridge
```

> **Hinweis:**
>
> * TLS-Zertifikate liegen in `/etc/letsencrypt` auf der VM
> * `nginx/conf.d` enth√§lt deine `server`-Configs
> * `nginx/htpasswd` enth√§lt die Basic-Auth-User

---

### b) Nginx-Config (`nginx/conf.d/sola.conf`)

```nginx
server {
    listen 80;
    server_name sola.example.com;

    # Redirect everything to HTTPS
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$host$request_uri;
    }
}

server {
    listen 443 ssl http2;
    server_name sola.example.com;

    ssl_certificate     /etc/letsencrypt/live/sola.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/sola.example.com/privkey.pem;

    ssl_protocols       TLSv1.2 TLSv1.3;
    ssl_prefer_server_ciphers on;

    # Basic Auth (zus√§tzlich zu App-Passwort)
    auth_basic           "Restricted Sola History";
    auth_basic_user_file /etc/nginx/htpasswd/sola_users;

    location / {
        proxy_pass         http://sola-history:8501;
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header   X-Forwarded-Proto $scheme;
    }
}
```

---

### c) Basic Auth User anlegen

Auf der VM (nicht im Container):

```bash
mkdir -p nginx/htpasswd
docker run --rm -it httpd:alpine htpasswd -nbB sola-admin 'DeinStarkesPasswort' \
  > nginx/htpasswd/sola_users
```

=> Nginx fragt dann HTTP Basic Auth ab **vor** der App.

---

### d) Let‚Äôs Encrypt ‚Äì erster Cert-Request (ganz kurz)

1. Einmalig Verzeichnis f√ºr Webroot anlegen:

```bash
sudo mkdir -p /var/www/certbot
sudo chown -R $USER /var/www/certbot
```

2. Tempor√§re Nginx-Config f√ºr ACME-Challenge (oder bestehenden 80er-Serverblock wie oben nutzen).

3. Certbot im Container einmal manuell laufen lassen:

```bash
docker run --rm -it \
  -v /etc/letsencrypt:/etc/letsencrypt \
  -v /var/www/certbot:/var/www/certbot \
  certbot/certbot certonly \
    --webroot \
    -w /var/www/certbot \
    -d sola.example.com \
    --email deine@mailadresse \
    --agree-tos \
    --no-eff-email
```

4. Danach `docker compose up -d` ‚Üí Nginx sieht die Zertifikate in `/etc/letsencrypt/live/sola.example.com/`.

5. **Renewal** kann sp√§ter mit Cron oder einem kleinen `certbot renew`-Container gemacht werden.

F√ºr deinen Scope reicht erstmal: **manuell erstellen, gelegentlich erneuern**.

---

## 2Ô∏è‚É£ Terraform-Draft ‚Äì OCI Compute + VCN + Security

Wir nehmen das Setup: **eine VM mit Public-IP**, darauf l√§uft dein `docker-compose` mit nginx + App.

### a) `variables.tf` (Vereinfacht)

```hcl
variable "compartment_ocid" {
  description = "OCI Compartment OCID"
  type        = string
}

variable "ssh_public_key" {
  description = "SSH public key for opc user"
  type        = string
}

variable "region" {
  description = "OCI Region"
  type        = string
  default     = "eu-zurich-1"
}

variable "cidr_vcn" {
  description = "VCN CIDR"
  type        = string
  default     = "10.20.0.0/16"
}

variable "cidr_subnet" {
  description = "Subnet CIDR"
  type        = string
  default     = "10.20.10.0/24"
}
```

---

### b) `main.tf` (stark gek√ºrzt, als Draft)

```hcl
provider "oci" {
  region = var.region
}

# VCN
resource "oci_core_vcn" "sola_vcn" {
  cidr_block     = var.cidr_vcn
  compartment_id = var.compartment_ocid
  display_name   = "sola-vcn"
}

resource "oci_core_internet_gateway" "igw" {
  compartment_id = var.compartment_ocid
  display_name   = "sola-igw"
  vcn_id         = oci_core_vcn.sola_vcn.id
  enabled        = true
}

resource "oci_core_route_table" "rt" {
  compartment_id = var.compartment_ocid
  vcn_id         = oci_core_vcn.sola_vcn.id
  display_name   = "sola-rt"

  route_rules {
    network_entity_id = oci_core_internet_gateway.igw.id
    destination       = "0.0.0.0/0"
    destination_type  = "CIDR_BLOCK"
  }
}

resource "oci_core_subnet" "public_subnet" {
  compartment_id      = var.compartment_ocid
  vcn_id              = oci_core_vcn.sola_vcn.id
  cidr_block          = var.cidr_subnet
  display_name        = "sola-public-subnet"
  route_table_id      = oci_core_route_table.rt.id
  dns_label           = "solapub"
  prohibit_public_ip_on_vnic = false
}

# Security List: 22, 80, 443 von deinem Netz
resource "oci_core_security_list" "sl_public" {
  compartment_id = var.compartment_ocid
  vcn_id         = oci_core_vcn.sola_vcn.id
  display_name   = "sola-sl-public"

  ingress_security_rules {
    protocol = "6"
    source   = "0.0.0.0/0"
    tcp_options {
      min = 80
      max = 80
    }
  }

  ingress_security_rules {
    protocol = "6"
    source   = "0.0.0.0/0"
    tcp_options {
      min = 443
      max = 443
    }
  }

  # optional: SSH nur von deiner IP
  ingress_security_rules {
    protocol = "6"
    source   = "<DEINE-IP>/32"
    tcp_options {
      min = 22
      max = 22
    }
  }

  egress_security_rules {
    protocol = "all"
    destination = "0.0.0.0/0"
  }
}

# Compute Instance
resource "oci_core_instance" "sola_vm" {
  compartment_id = var.compartment_ocid
  availability_domain = data.oci_identity_availability_domains.ads.availability_domains[0].name
  display_name   = "sola-history-vm"

  shape = "VM.Standard.E3.Flex"
  shape_config {
    ocpus         = 1
    memory_in_gbs = 4
  }

  create_vnic_details {
    subnet_id        = oci_core_subnet.public_subnet.id
    display_name     = "sola-vnic"
    assign_public_ip = true
    hostname_label   = "sola"
  }

  metadata = {
    ssh_authorized_keys = var.ssh_public_key

    # optional: cloud-init, um Docker & docker-compose vorzuinstallieren
    user_data = base64encode(<<EOF
#cloud-config
packages:
  - docker
runcmd:
  - systemctl enable docker
  - systemctl start docker
EOF
    )
  }

  source_details {
    source_type = "image"
    # Oracle Linux 8/9 Image OCID f√ºr deine Region eintragen
    source_id   = "<ORACLE_LINUX_IMAGE_OCID>"
  }
}
```

Damit hast du:

* VCN + Subnet
* Internet Gateway
* Security List
* VM mit Public-IP

Alles weitere: via SSH auf die VM ‚Üí `docker-compose.yml` deployen ‚Üí `docker compose up -d`.

---

## 3Ô∏è‚É£ Security & Data-Governance ‚Äì Kurzfassung

### a) Daten-Trennung

* **App-Repo** (sola-history-app):

  * Kein PII, keine JSONs mit echten Namen
  * Nur Code, Schema, Tools
* **Data-Repo** (sola-history-data):

  * Tools & Pipelines
  * Rohdaten **nicht im Git**, nur lokal / verschl√ºsselt

### b) Object Storage Governance

* **Bucket `sola-history-data`**:

  * Server-side encryption (Standard in OCI)
  * IAM-Policy:

    * Nur definierte Gruppen / Dynamic Groups d√ºrfen lesen
    * Schreibrechte nur von Data-Pipeline / Admin
* **Dynamic Group** f√ºr Compute-Instances/Container Instances:

  * ‚Äûdarf `get_object` auf Bucket ausf√ºhren‚Äú

### c) Secrets & Credentials

* Keinerlei Passw√∂rter/Keys im Git:

  * `SOLA_APP_PASSWORD` ‚Üí OCI Vault Secret oder GitHub Secret
  * OCI API Keys ‚Üí GitHub Secrets (nur im Data-Repo)
* Nginx Basic Auth:

  * `.htpasswd` nur auf der VM (nicht im Git)

### d) Logging & Monitoring

* Nginx-Logs: Zugriff √ºberwachen (IP, Pfade, Statuscodes)
* App-Logs: im Container, optional in OCI Logging einspeisen
* Keine sensiblen Daten in Logs (keine E-Mails, keine Telefone loggen)

---

## 4Ô∏è‚É£ Branching & Release-Konzept

### a) App Repo (`sola-history-app`)

**Branches:**

* `main`: stabil, Produktion
* `develop`: Integration / neue Features
* `feature/*`: kurzlebige Feature-Branches

**Releases:**

* Tags wie `v1.0.0`, `v1.1.0`, ‚Ä¶
* GitHub Action baut & pusht Image mit Tag:

  * `ghcr.io/<user>/sola-history-app:latest`
  * `ghcr.io/<user>/sola-history-app:v1.1.0`

**Deployment:**

* Prod-Deployment triggert auf Tag `v*`
* Optional: Staging-Instance mit `develop`-Image

---

### b) Data Repo (`sola-history-data`)

Daten √§ndern sich seltener und sind versioniert eher **zeitbasiert** als ‚ÄûFeature‚Äú.

**Branches:**

* `main`: aktueller Datenstand
* `datafix/*`: tempor√§re Branches f√ºr Korrekturen

**Tags/Snapshots:**

* `data-YYYYMMDD`
  z.B. `data-2025-05-10` = Stand der JSONs nach SOLA 2025.

**Pipeline:**

* Push auf `main` oder manuelles `workflow_dispatch`:

  * `import_excel.py`
  * `validate_schema.py`
  * `upload_data_to_oci.sh` ‚Üí Bucket `sola-history-data`

Die App holt sich immer die ‚Äûaktuelle‚Äú Variante (z.B. `latest.json` im Bucket).
Wenn du Snapshots willst, kannst du Prefixe nutzen:

* `current/runners.json`
* `snapshots/2025-05-10/runners.json`

---

Wenn du magst, k√∂nnen wir als N√§chstes:

* dein **konkretes `docker-compose.yml`** f√ºr die VM fertigstellen (inkl. Proxy, App, Certbot)
* oder ein kleines `doc/architecture.md` schreiben, das genau diese Punkte (App, Data, Nginx, OCI) auf 1‚Äì2 Seiten zusammenfasst.



Hier ist **eine saubere, professionelle und sofort verwendbare**
`doc/architecture.md` f√ºr dein Projekt ‚Äì klar strukturiert, vollst√§ndig, GitHub-ready.

---

# `doc/architecture.md`


---

Wenn du willst, kann ich zus√§tzlich erstellen:

‚úÖ `doc/deployment.md`
‚úÖ vollst√§ndige Terraform-Module
‚úÖ komplettes `docker-compose.yml` f√ºr die VM
‚úÖ GH Actions f√ºr App + Data
‚úÖ Sicherheitskonzept (ISO 27001-like)

Sag einfach *"Bitte Teil 2"* oder *"mach deployment.md"* üòä


Kurz & klar ‚Äî **ja**, du kannst die Sola-History-App **vollst√§ndig auf einer OCI Free Tier VM** betreiben.
Hier ist der **saubere Entscheidungsrahmen**, inklusive DNS-Strategie, SSL, Kosten & Best Practices.

---

# ‚úÖ 1. Kann die VM ‚ÄûAlways Free‚Äú sein?

**Ja.**
Die App ist:

* CPU-leicht
* Speicherleicht (~100‚Äì300 MB RAM)
* Keine hohe Last
* Kein starker I/O

üëâ Die **OCI Free Tier VM.Standard.A1.Flex (Arm)** ist perfekt.

### **Empfohlene Specs**

| Component   | Value                                      |
| ----------- | ------------------------------------------ |
| Shape       | **VM.Standard.A1.Flex** (Arm, Always Free) |
| CPUs        | 1 OCPU                                     |
| Memory      | 2‚Äì4 GB                                     |
| Boot Volume | 50 GB (Always Free erlaubt bis zu 200 GB)  |
| OS          | Oracle Linux 8 / 9                         |

Kosten: **0 CHF / 0 EUR**
‚Üí Free Tier.

---

# ‚úÖ 2. DNS / Hostname ‚Äî 3 m√∂gliche Varianten

## **Option A ‚Äî Kostenlos via xip.io / sslip.io (simpel)**

Du brauchst *keine eigene Domain*.

**Beispiel:**

```
https://130-61-42-100.sslip.io
```

SSL funktioniert via Let's Encrypt ‚Üí **funktioniert 100% ohne zus√§tzliche Konfiguration**.

**Vorteile:**

* Kein Domain-Kauf
* Einfach
* Let's Encrypt funktioniert

**Nachteile:**

* Nicht ‚Äûsch√∂n‚Äú
* Kein Branding

üëâ **F√ºr schnellen Start absolut ideal.**

---

## **Option B ‚Äî Eigene Domain (empfohlen f√ºr langfristig)**

Du nutzt z.B.:

```
sola.oehrlis.ch
sola-history.ch
history.sola-runs.com
```

### Schritte:

1. Domain kaufen (falls nicht vorhanden)
2. A-Record auf √∂ffentliche IP der OCI VM
3. Nginx + Certbot generiert SSL automatisch

**Kosten:** Domain ~10‚Äì15 CHF/Jahr
**Vorteile:** Professioneller, stabil.

---

## **Option C ‚Äî OCI DNS (kostenpflichtig in Enterprise)**

Nur sinnvoll bei mehreren Zonen oder komplexem Setup.

‚û°Ô∏è **F√ºr dein Projekt nicht n√∂tig.**

---

# ‚úÖ 3. Wie l√§uft SSL auf der Free Tier VM?

Du hast zwei Varianten:

---

## Variante 1 ‚Äî **Certbot im Container (empfohlen)**

`docker-compose.yml`:

```
nginx
certbot
sola-history-app
```

Workflow:

1. Certbot holt Let's Encrypt Zertifikate
2. Nginx l√§dt sie
3. Cron / certbot renew automatisch

Kosten: **0**

---

## Variante 2 ‚Äî OCI Loadbalancer (Nicht Free Tier)

**Nicht n√∂tig**, ausser du willst sp√§ter skalieren.

---

# ‚úÖ 4. Wie sieht ein typisches Deployment aus?

```
Incoming User
    ‚îÇ
HTTPS (443)
    ‚ñº
Nginx Reverse Proxy (on VM)
    ‚ñº
sola-history-app container (Streamlit)
    ‚ñº
OCI Object Storage (data bucket)
```

Alles auf **einer Free Tier VM**.

---

# ‚úÖ 5. DNS decision ‚Äî What should YOU choose?

### ‚≠ê Empfehlung f√ºr dich:

### **Phase 1 ‚Äì Development / Internal Use**

‚û°Ô∏è Nutze **sslip.io**

Beispiel:

```
https://130-61-42-100.sslip.io
```

### **Phase 2 ‚Äì Public or Team Deployment**

‚û°Ô∏è Domain:

```
sola-history.ch
sola.oehrlis.ch
sola-team.ch
```

Kosten minimal, Wirkung gro√ü.

---

# ‚úÖ 6. Konkreter Umsetzungsvorschlag

### 6.1 Reserviere statische IP in OCI

```
Public IP: 130.61.42.100
```

### 6.2 Use DNS hostname

```
sola.130-61-42-100.sslip.io
```

### 6.3 docker-compose bereitstellen:

```
app
nginx
certbot
```

### 6.4 Certbot generiert Zertifikate:

```
certbot certonly --webroot -w /var/www/certbot -d 130-61-42-100.sslip.io
```

### 6.5 Your app is now accessible:

```
https://130-61-42-100.sslip.io
```

Gratis, stabil, ohne Domain.

---

# ‚ùì Was m√∂chtest du nutzen?

Ich empfehle folgende Frage:

## **M√∂chtest du:**

1. **Kostenlos starten** ‚Üí sslip.io
2. **Professionelles Deployment** ‚Üí eigene Domain
3. **Ich schlage eine Domain vor, die zu deinem Projekt passt**
4. **Wildcard domain** (falls du sp√§ter mehrere Services planst)

---

# üåü Bonus: Wenn du willst, mache ich dir direkt:

‚úì fertiges DNS-Setup (f√ºr Option A oder B)
‚úì fertiges docker-compose f√ºr Nginx/Certbot/App
‚úì README f√ºr Deployment
‚úì Terraform f√ºr vollst√§ndige VM-Provisionierung

Sag einfach:

üëâ **‚ÄúBitte Deployment-Paket erstellen‚Äù**

Perfekt ‚Äî **oradba.ch** ist eine hervorragende Domain f√ºr das Projekt.
Damit l√§sst sich ein **sauberes, professionelles und dennoch simples Deployment** aufbauen.

---

# ‚úÖ Empfehlung f√ºr deine Subdomain

Du willst etwas **kurzes**, **eindeutiges** und **ohne Konflikte** in Zukunft.

Ich schlage drei Varianten vor:

### **1Ô∏è‚É£ sola.oradba.ch**

Kurz, eindeutig, gut merkbar.
‚Üí *Empfehlung Nr. 1*

### **2Ô∏è‚É£ history.sola.oradba.ch**

Falls du sp√§ter weitere SOLA-Dienste baust.

### **3Ô∏è‚É£ sola-history.oradba.ch**

Selbsterkl√§rend, etwas l√§nger.

üëâ **Meine klare Empfehlung:**

### ‚≠ê **`sola.oradba.ch`**

---

# üîß Schritte f√ºr die Subdomain

## **Step 1 ‚Äî Statische IP der Free Tier VM reservieren**

In OCI:

```
Networking ‚Üí Public IPs ‚Üí Reserve Public IP
```

Beispiel:

```
Public IP: 130.61.42.100
```

---

## **Step 2 ‚Äî DNS-Record in oradba.ch anlegen**

Bei deinem DNS-Provider (vermutlich hosttech oder cloudflare):

### **A-Record:**

| Type | Name           | Value         | TTL  |
| ---- | -------------- | ------------- | ---- |
| A    | sola.oradba.ch | 130.61.42.100 | auto |

---

## **Step 3 ‚Äî SSL/HTTPS einrichten**

Mit **Nginx + Certbot** im Docker-Compose (kostet 0 CHF).

### Certbot holt Zertifikat:

```
certbot --nginx -d sola.oradba.ch
```

Oder via Webroot:

```
certbot certonly --webroot -w /var/www/certbot -d sola.oradba.ch
```

---

# üì¶ Was ich dir als N√§chstes bauen kann

Wenn du sagst **‚ÄûGo‚Äú**, erstelle ich vollst√§ndig:

---

## **1. Auslieferbares Deployment-Paket (ready to copy)**

### docker-compose.yml

‚úî sola-history-app
‚úî nginx reverse proxy
‚úî certbot
‚úî automatische SSL-Erneuerung
‚úî Healthchecks
‚úî Logging

---

## **2. Fertiges nginx.conf**

Mit:

* SSL
* Reverse Proxy
* Rate limiting
* Gzip
* Basic Auth m√∂glich

---

## **3. domain-specific README.md**

```
How to deploy sola.oradba.ch on OCI Free Tier
```

Mit allen Befehlen:

* Reserviere IP
* DNS setzen
* Server h√§rten
* Certbot aktivieren
* Logs pr√ºfen

---

## **4. Optional: Terraform Modul**

Damit bekommst du:

* VM
* Security List
* Public IP
* Cloud-Init Deployment
* Docker + Compose Install

Alles in einem Befehl:

```
terraform apply
```

---

# üí¨ Noch 2 Fragen bevor ich das Deployment-Paket erstelle:

### **1Ô∏è‚É£ Welche Subdomain m√∂chtest du verwenden?**

* sola.oradba.ch
* sola-history.oradba.ch
* history.sola.oradba.ch
* etwas anderes?

üëâ *Ich empfehle:* **sola.oradba.ch**

---

### **2Ô∏è‚É£ M√∂chtest du Basic Auth zus√§tzlich zum App-Passwort?**

(z. B. doppelte Absicherung √ºber nginx)

Optionen:

| Option                    | Beschreibung                    |
| ------------------------- | ------------------------------- |
| üîê **Basic Auth (nginx)** | Benutzer + Passwort vor der App |
| üîì Nur App-Passwort       | Einfacher, aber weniger sicher  |
| üîë OAuth (Google Login)   | Komfortabel, aber mehr Aufwand  |

---

Sobald du antwortest, mache ich:

üëâ **‚ÄûDeployment Package ‚Äì sola.oradba.ch‚Äú**
inkl. aller Dateien & Dokumentation.

Sehr cool, dann machen wir jetzt ein **konkretes Deployment Package f√ºr `sola.oradba.ch`** ‚Äì ohne Basic Auth (kommt sp√§ter), nur mit:

* Free Tier VM auf OCI
* Docker + docker-compose
* Nginx als Reverse Proxy mit HTTPS (Let‚Äôs Encrypt)
* Deinem Sola-App-Container

Ich baue dir das so, dass du es 1:1 auf der VM ablegen kannst.

---

## 1. Verzeichnisstruktur auf der VM

Auf der VM z.B. unter `/opt/sola-history`:

```text
/opt/sola-history
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ nginx/
    ‚îú‚îÄ‚îÄ conf.d/
    ‚îÇ   ‚îî‚îÄ‚îÄ sola.conf
    ‚îî‚îÄ‚îÄ webroot/              # f√ºr Let's Encrypt HTTP-01 Challenge
```

Erstellen:

```bash
sudo mkdir -p /opt/sola-history/nginx/conf.d
sudo mkdir -p /opt/sola-history/nginx/webroot
sudo chown -R $USER:$USER /opt/sola-history
cd /opt/sola-history
```

---

## 2. `.env` ‚Äì Umgebungsvariablen f√ºr docker-compose

Datei: `/opt/sola-history/.env`

```env
# App password for the Streamlit login
SOLA_APP_PASSWORD=change_me_please

# OCI Object Storage settings (f√ºr fetch_data.py im Container)
SOLA_DATA_BUCKET=sola-history-data
# Namespace kannst du leer lassen, wenn fetch_data.py ihn automatisch ermitteln soll
SOLA_DATA_NAMESPACE=

# Domain name
VIRTUAL_HOST=sola.oradba.ch
```

> `SOLA_DATA_BUCKET` muss zu deinem Bucket-Namen passen.
> `SOLA_DATA_NAMESPACE` kannst du sp√§ter setzen, wenn du ihn kennst ‚Äì ist aber optional.

---

## 3. `docker-compose.yml`

Datei: `/opt/sola-history/docker-compose.yml`

```yaml
version: "3.9"

services:
  sola-history:
    image: ghcr.io/oehrlis/sola-history-app:latest
    container_name: sola-history
    restart: unless-stopped
    environment:
      - SOLA_APP_PASSWORD=${SOLA_APP_PASSWORD}
      - SOLA_DATA_BUCKET=${SOLA_DATA_BUCKET}
      - SOLA_DATA_NAMESPACE=${SOLA_DATA_NAMESPACE}
    # App h√∂rt intern auf 8501
    expose:
      - "8501"
    networks:
      - sola-net
    # optional: Persistente Overrides / Logs
    volumes:
      - sola-data:/app/data/processed

  nginx:
    image: nginx:alpine
    container_name: sola-nginx
    restart: unless-stopped
    depends_on:
      - sola-history
    ports:
      - "80:80"
      - "443:443"
    networks:
      - sola-net
    volumes:
      # Nginx Config
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      # Webroot f√ºr ACME-Challenges
      - ./nginx/webroot:/var/www/certbot:ro
      # Let's Encrypt Zertifikate vom Host
      - /etc/letsencrypt:/etc/letsencrypt:ro

networks:
  sola-net:
    driver: bridge

volumes:
  sola-data:
```

> **Hinweis zum Image:** ich habe `ghcr.io/oehrlis/sola-history-app:latest` angenommen.
> Falls dein Repo anders heisst, passe die Image-URL an.

---

## 4. Nginx-Konfiguration f√ºr `sola.oradba.ch`

Datei: `/opt/sola-history/nginx/conf.d/sola.conf`

Zuerst Version mit HTTP + ACME-Challenge + HTTPS-Redirect + Proxy:

```nginx
# HTTP: nur f√ºr Let's Encrypt Challenge und Redirect auf HTTPS
server {
    listen 80;
    server_name sola.oradba.ch;

    # ACME HTTP-01 Challenge f√ºr certbot
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$host$request_uri;
    }
}

# HTTPS: Reverse Proxy zur Streamlit-App
server {
    listen 443 ssl http2;
    server_name sola.oradba.ch;

    # Diese Pfade werden von Certbot erzeugt
    ssl_certificate     /etc/letsencrypt/live/sola.oradba.ch/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/sola.oradba.ch/privkey.pem;

    ssl_protocols       TLSv1.2 TLSv1.3;
    ssl_prefer_server_ciphers on;

    # Optional: etwas Logging
    access_log /var/log/nginx/sola_access.log;
    error_log  /var/log/nginx/sola_error.log;

    # Sp√§ter kannst du hier Basic Auth erg√§nzen

    location / {
        proxy_pass         http://sola-history:8501;
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header   X-Forwarded-Proto $scheme;
    }
}
```

> Die TLS-Pfade funktionieren erst, **nachdem** du Certbot einmal laufen gelassen hast.

---

## 5. Erstes Starten ohne Zertifikate

Zuerst Nginx und App hochfahren (HTTP funktioniert, HTTPS noch nicht):

```bash
cd /opt/sola-history
docker compose pull
docker compose up -d
```

Jetzt sollte unter `http://<VM-IP>` bereits ein Nginx-Fehler oder Redirect laufen.
Wichtig ist: Port 80 funktioniert f√ºr die ACME-Challenge.

---

## 6. Let‚Äôs Encrypt Zertifikat holen (einmalig)

Auf der VM (nicht im Container):

```bash
sudo mkdir -p /etc/letsencrypt
sudo chown -R $USER:$USER /etc/letsencrypt
```

Dann Certbot als Docker-Container mit Webroot:

```bash
docker run --rm -it \
  -v /etc/letsencrypt:/etc/letsencrypt \
  -v /opt/sola-history/nginx/webroot:/var/www/certbot \
  certbot/certbot certonly \
    --webroot \
    -w /var/www/certbot \
    -d sola.oradba.ch \
    --email deine.email@oradba.ch \
    --agree-tos \
    --no-eff-email
```

Wenn das durchl√§uft, hast du Zertifikate unter:

```text
/etc/letsencrypt/live/sola.oradba.ch/
  ‚îú‚îÄ‚îÄ fullchain.pem
  ‚îî‚îÄ‚îÄ privkey.pem
```

Jetzt Nginx neu starten:

```bash
docker compose restart nginx
```

Ab jetzt:
üëâ `https://sola.oradba.ch` sollte erreichbar sein
üëâ Streamlit-App h√§ngt hinter Nginx, Passwortschutz macht die App selbst (`SOLA_APP_PASSWORD`)

---

## 7. Zertifikats-Erneuerung (Renewal)

Einmal pro Tag per Cron auf der VM (als root oder user mit Zugriff):

```bash
sudo crontab -e
```

Eintrag:

```cron
# Renew Let's Encrypt certs for sola.oradba.ch daily at 03:30
30 3 * * * docker run --rm \
  -v /etc/letsencrypt:/etc/letsencrypt \
  -v /opt/sola-history/nginx/webroot:/var/www/certbot \
  certbot/certbot renew --webroot -w /var/www/certbot --quiet && \
  docker compose -f /opt/sola-history/docker-compose.yml reload nginx
```

Falls `reload` nicht geht, kannst du auch `restart nginx` verwenden, ist halt etwas h√§rter.

---

## 8. Wie geht‚Äôs weiter? (Basic Auth & OAuth)

### Jetzt:

* Authentisierung nur √ºber `SOLA_APP_PASSWORD` in der App.
* Zugriff √ºber HTTPS abgesichert, mit Let‚Äôs Encrypt Zertifikat.
* Domain: `sola.oradba.ch`.

### Sp√§ter:

1. **Basic Auth in Nginx** erg√§nzen (einfach):

   * `auth_basic` + `auth_basic_user_file` in der HTTPS-Server-Section
   * `.htpasswd` unter `/opt/sola-history/nginx/htpasswd`

2. **OAuth (Google / AzureAD)**:

   * Vor Nginx z.B. `oauth2-proxy` Container h√§ngen
   * Nginx ‚Üí oauth2-proxy ‚Üí sola-history
     (k√∂nnen wir in einem n√§chsten Schritt sauber designen)

---
scripts/project_issues.txt

Wenn du magst, k√∂nnen wir als N√§chstes das `docker-compose.yml` und den Image-Namen exakt auf dein reales GitHub-Repo anpassen ‚Äì sobald du den finalen Namen hast.
::contentReference[oaicite:0]{index=0}
```
